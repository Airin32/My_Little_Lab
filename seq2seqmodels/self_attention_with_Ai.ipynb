{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_attention (Q,K,V) :\n",
    "    d_k = tf.cast(tf.shape(K)[-1],tf.float32)\n",
    "    scores = tf.matmul(Q,K,transpose_b=True)/tf.math.sqrt(d_k)\n",
    "    attention_weight = tf.nn.softmax(scores,axis=-1)\n",
    "    output = tf.matmul(attention_weight,V)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = tf.random.normal([1, 3, 4])\n",
    "K = tf.random.normal([1, 3, 4])\n",
    "V = tf.random.normal([1, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : [[[-1.9292568   1.2269667   0.6370855   0.268685  ]\n",
      "  [ 0.09105452 -0.64205617 -1.4091802   0.6219789 ]\n",
      "  [-0.04484814  1.2287714   0.5167272  -0.01811061]]]\n",
      "K : [[[-0.96645766 -0.5565629  -0.45644137  0.18691523]\n",
      "  [-1.6269337  -1.5180072   0.01363173 -1.1714674 ]\n",
      "  [-0.10310423  0.24987963  0.7463436  -1.4164997 ]]]\n",
      "V : [[[-0.3739626  -0.70063055  0.898552   -0.315544  ]\n",
      "  [-0.04521862  0.23821616  0.52189904 -0.10142639]\n",
      "  [ 0.7520454   0.61420715 -0.39475915 -0.6265716 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Q : {Q}\")\n",
    "print(f\"K : {K}\")\n",
    "print(f\"V : {V}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 4), dtype=float32, numpy=\n",
       "array([[[ 0.07502148,  0.02067154,  0.38318983, -0.33131033],\n",
       "        [-0.13379401, -0.23168473,  0.6230169 , -0.27831373],\n",
       "        [ 0.3288317 ,  0.21215089,  0.09149134, -0.45905122]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_dot_attention(Q,K,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.0591817   0.50720805 -0.11987717 -0.11517995]\n",
      "  [ 0.92439175  0.30485007 -0.04524641 -0.04805614]\n",
      "  [ 0.899948    0.32792068 -0.10444834 -0.0222591 ]]], shape=(1, 3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def scaled_dot_product_attention(Q, K, V):\n",
    "    d_k = tf.cast(tf.shape(K)[-1], tf.float32)\n",
    "    scores = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(d_k)\n",
    "    attention_weights = tf.nn.softmax(scores, axis=-1)\n",
    "    output = tf.matmul(attention_weights, V)\n",
    "    return output\n",
    "\n",
    "# Contoh input (3 kata dengan dimensi 4)\n",
    "Q = tf.random.normal([1, 3, 4])\n",
    "K = tf.random.normal([1, 3, 4])\n",
    "V = tf.random.normal([1, 3, 4])\n",
    "\n",
    "output = scaled_dot_product_attention(Q, K, V)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaled_dot_Attention (tf.keras.layers.Layer) :\n",
    "    def __init__ (self):\n",
    "        super(Scaled_dot_Attention,self).__init__()\n",
    "\n",
    "    def call(self,Q,K,V,mask=None) :\n",
    "        d_k = tf.cast(td.shape(K)[-1],tf.float32) \n",
    "        scores = tf.matmul(Q,K,transpose_b=True)/tf.math.sqrt(d_k)\n",
    "        if mask is not None :\n",
    "            scores += (mask * -1e9)\n",
    "        weight = tf.nn.softmax(scores,axis=-1)\n",
    "        output = tf.matmul(weight,V)\n",
    "        return output,weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention (tf.keras.layers.Layer) :\n",
    "    def __init__ (self,num_heads,d_model) :\n",
    "        super(MultiheadAttention,self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        self.Wq = keras.layers.Dense(d_model)\n",
    "        self.Wk = keras.layers.Dense(d_model)\n",
    "        self.Wv = keras.layers.Dense(d_model)\n",
    "        self.dense = keras.layers.Dense(d_model)\n",
    "        self.attention = Scaled_dot_Attention()\n",
    "    \n",
    "    def splitsHeads (self,x,batch_size):\n",
    "        x = tf.reshape(x,(batch_size,-1,self.num_heads,self.depth))\n",
    "        return tf.transpose(x,perm=[0,2,1,3])\n",
    "    \n",
    "    def call (self,Q,K,V,mask=None) :\n",
    "        batch_size = tf.shape(Q)[0]\n",
    "        Q = self.splitsHeads(self.Wq, batch_size)\n",
    "        K = self.splitsHeads(self.Wk, batch_size)\n",
    "        V = self.splitsHeads(self.Wv, batch_size)\n",
    "\n",
    "        output,attention_weight = self.attention(Q,K,V,mask)\n",
    "        output = tf.transpose(output,perm=[0,2,1,3])\n",
    "        output = tf.reshape(output,(batch_size,-1,self.d_model))\n",
    "        output = tf.dense(output)\n",
    "        \n",
    "        return output,attention_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_Layers (keras.layers.Layer) :\n",
    "    def __init__ (self,d_model,num_heads,dff,rate=0.1) :\n",
    "        super(Encoder_Layers,self).__init__()\n",
    "        self.mha = MultiheadAttention(num_heads=num_heads,d_model=d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            keras.layers.Dense(dff,activation='relu'),\n",
    "            keras.layers.Dense(d_model)\n",
    "        ])\n",
    "\n",
    "        self.layernormal1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernormal2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "\n",
    "    def call (self,x,mask) :\n",
    "        attn_output = self.mha(x,x,x,mask)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernormal1(x + attn_output)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.layernormal2(out1 + ffn_output)\n",
    "        \n",
    "        return out2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer (keras.layers.Layer) :\n",
    "    def __init__ (self,d_model,num_heads, dff,rate=0.1) :\n",
    "        super(DecoderLayer,self).__init__()\n",
    "        self.mha1 = MultiheadAttention(num_heads=num_heads,d_model=d_model)\n",
    "        self.mha2 = MultiheadAttention(num_heads=num_heads,d_model=d_model)\n",
    "\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [\n",
    "                keras.layers.Dense(dff,activation='relu'),\n",
    "                keras.layers.Dense(d_model)\n",
    "\n",
    "            ]\n",
    "        )\n",
    "        self.layernormal1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernormal2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernormal3 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "        self.dropout3 = keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self,x,enc_output,look_ahead_mask,padding_mask) :\n",
    "        attn1, _ = self.mha1(x, x, x, look_ahead_mask)  # Masked Self-Attention\n",
    "        attn1 = self.dropout1(attn1)\n",
    "        out1 = self.layernorm1(x + attn1)\n",
    "\n",
    "        attn2, _ = self.mha2(out1, enc_output, enc_output, padding_mask)  # Encoder-Decoder Attention\n",
    "        attn2 = self.dropout2(attn2)\n",
    "        out2 = self.layernorm2(out1 + attn2)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # Feed Forward Network\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        out3 = self.layernorm3(out2 + ffn_output)\n",
    "\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Tentukan dimensi model (ukuran vektor setiap kata)\n",
    "d_model = 128  # Ukuran embedding\n",
    "num_heads = 8  # Jumlah kepala attention\n",
    "dff = 512  # Ukuran hidden layer pada FFN\n",
    "dropout_rate = 0.1  # Dropout untuk regularisasi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation='relu'),\n",
    "            tf.keras.layers.Dense(d_model)\n",
    "        ])\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output = self.mha(x, x, x, attention_mask=mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.mha1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.mha2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation='relu'),\n",
    "            tf.keras.layers.Dense(d_model)\n",
    "        ])\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attn1 = self.mha1(x, x, x, attention_mask=look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(x + attn1)\n",
    "\n",
    "        attn2 = self.mha2(out1, enc_output, enc_output, attention_mask=padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(out1 + attn2)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(out2 + ffn_output)\n",
    "\n",
    "        return out3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, dropout_rate):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        for enc_layer in self.enc_layers:\n",
    "            x = enc_layer(x, training, mask)\n",
    "        return x\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, dropout_rate):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        for dec_layer in self.dec_layers:\n",
    "            x = dec_layer(x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, dropout_rate):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, dropout_rate)\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, dropout_rate)\n",
    "        self.final_layer = tf.keras.layers.Dense(d_model)  # Layer akhir untuk output\n",
    "\n",
    "    def call(self, enc_input, dec_input, training, enc_mask, look_ahead_mask, dec_mask):\n",
    "        enc_output = self.encoder(enc_input, training, enc_mask)\n",
    "        dec_output = self.decoder(dec_input, enc_output, training, look_ahead_mask, dec_mask)\n",
    "        final_output = self.final_layer(dec_output)  # Proses ke layer akhir\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat input acak (seolah-olah ini adalah embedding dari token kata)\n",
    "batch_size = 2  # Contoh 2 kalimat\n",
    "seq_length = 10  # Maksimal 10 kata per kalimat\n",
    "dummy_enc_input = tf.random.uniform((batch_size, seq_length, d_model))  # Encoder input\n",
    "dummy_dec_input = tf.random.uniform((batch_size, seq_length, d_model))  # Decoder input\n",
    "\n",
    "# Buat Transformer dengan 2 layer Encoder & Decoder\n",
    "transformer = Transformer(num_layers=2, d_model=d_model, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Transformer.call().\n\n\u001b[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: False (of type <class 'bool'>)\u001b[0m\n\nArguments received by Transformer.call():\n  • enc_input=tf.Tensor(shape=(2, 10, 128), dtype=float32)\n  • dec_input=tf.Tensor(shape=(2, 10, 128), dtype=float32)\n  • training=False\n  • enc_mask=None\n  • look_ahead_mask=None\n  • dec_mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Jalankan model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_enc_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_dec_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[43menc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput Transformer shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Harusnya (batch_size, seq_length, d_model)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m, in \u001b[0;36mTransformer.call\u001b[1;34m(self, enc_input, dec_input, training, enc_mask, look_ahead_mask, dec_mask)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, enc_input, dec_input, training, enc_mask, look_ahead_mask, dec_mask):\n\u001b[1;32m----> 9\u001b[0m     enc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     dec_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(dec_input, enc_output, training, look_ahead_mask, dec_mask)\n\u001b[0;32m     11\u001b[0m     final_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer(dec_output)  \u001b[38;5;66;03m# Proses ke layer akhir\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Transformer.call().\n\n\u001b[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: False (of type <class 'bool'>)\u001b[0m\n\nArguments received by Transformer.call():\n  • enc_input=tf.Tensor(shape=(2, 10, 128), dtype=float32)\n  • dec_input=tf.Tensor(shape=(2, 10, 128), dtype=float32)\n  • training=False\n  • enc_mask=None\n  • look_ahead_mask=None\n  • dec_mask=None"
     ]
    }
   ],
   "source": [
    "# Jalankan model\n",
    "output = transformer(dummy_enc_input, dummy_dec_input, training=False, \n",
    "                     enc_mask=None, look_ahead_mask=None, dec_mask=None)\n",
    "\n",
    "print(\"Output Transformer shape:\", output.shape)  # Harusnya (batch_size, seq_length, d_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
