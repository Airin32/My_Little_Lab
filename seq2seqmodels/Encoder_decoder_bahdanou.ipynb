{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Dense,LSTM,Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahDanau_attention(tf.keras.layers.Layer) :\n",
    "    def __init__ (self,units,verbose=0):\n",
    "        super(BahDanau_attention, self).__init__()\n",
    "        self.__W1 = keras.layers.Dense(units)\n",
    "        self.__W2 = keras.layers.Dense(units)\n",
    "        self.__V = keras.layers.Dense(1)\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def call (self,query,values) :\n",
    "        if self.verbose :\n",
    "            print(\"\\n********** Bahdanau Start ***********\")\n",
    "            print(\"query (decoder hidden state) : (batch_size,hidden size)\", query.shape)\n",
    "            print(\"values (encoder all hidden state ) : (batch_size,max_len,hidden_size)\",values.shape)\n",
    "        query_with_time_axis = tf.expand_dims(query,1)\n",
    "        if self.verbose :\n",
    "            print(\"query_with_time_axis : (batch_size,1,hidden size)\",query_with_time_axis.shape)\n",
    "            score = self.V(tf.nn.tanh(self.__W1(query_with_time_axis) + self.__W2(values)))\n",
    "\n",
    "        if self.verbose :\n",
    "            print(\"score : (batch_size,1,1)\", score.shape)\n",
    "            attention_weight = tf.nn.softmax(score,axis=1)\n",
    "        \n",
    "        if self.verbose :\n",
    "            print(\"attention_weight : (batch_size,1,max_len)\", attention_weight.shape)\n",
    "            context_vector = attention_weight * values\n",
    "        if self.verbose :\n",
    "            print(\"context_vector : (batch_size,max_len,hidden_size)\", context_vector.shape)\n",
    "        context_vector = tf.reduce_sum(context_vector,axis=1)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"context_verctor after reduce sum : (batch_size,max_length,hidden_size) \",context_vector.shape)\n",
    "            print(\"\\n*******Bahdanau Is End*******\")\n",
    "        return context_vector,attention_weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random () :\n",
    "    return [np.random.randint(0,9) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [make_random() for i in range(3000)]\n",
    "Y = [make_random() for i in range(3000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = keras.utils.to_categorical(X,num_classes=10)\n",
    "Ys = keras.utils.to_categorical(Y,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m states \u001b[38;5;241m=\u001b[39m encoder_states\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m) :\n\u001b[1;32m---> 18\u001b[0m     context_vector,attention_weight \u001b[38;5;241m=\u001b[39m \u001b[43mattention\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([context_vector,inputs],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m     decoder_outputs,state_h,state_c \u001b[38;5;241m=\u001b[39m decoder_lstm(inputs,initial_state\u001b[38;5;241m=\u001b[39mstates)\n",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m, in \u001b[0;36mBahDanau_attention.call\u001b[1;34m(self, query, values)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery (decoder hidden state) : (batch_size,hidden size)\u001b[39m\u001b[38;5;124m\"\u001b[39m, query\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues (encoder all hidden state ) : (batch_size,max_len,hidden_size)\u001b[39m\u001b[38;5;124m\"\u001b[39m,values\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 14\u001b[0m query_with_time_axis \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose :\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_with_time_axis : (batch_size,1,hidden size)\u001b[39m\u001b[38;5;124m\"\u001b[39m,query_with_time_axis\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\common\\keras_tensor.py:138\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[1;34m(self, dtype, name)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.operations`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "verbose = 0\n",
    "batch_size = 1\n",
    "encoder_inputs = keras.Input(shape=(4,10))\n",
    "encoder_lstm = keras.layers.LSTM(32,return_state=True)\n",
    "encoder_outputs,encoder_state_h,encoder_state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [encoder_state_h,encoder_state_c]\n",
    "attention = BahDanau_attention(32,verbose=verbose)\n",
    "decoder_inputs = keras.Input(shape=(1,(4+32)))\n",
    "decoder_lstm = keras.layers.LSTM(32,return_state=True,return_sequences=True)\n",
    "decoder_dense = keras.layers.Dense(10,activation='softmax')\n",
    "\n",
    "all_input = list()\n",
    "inputs = np.zeros((batch_size,1,10))\n",
    "inputs[:,0,0] = 1\n",
    "decoder_outputs = encoder_state_h\n",
    "states = encoder_states\n",
    "for _ in range(4) :\n",
    "    context_vector,attention_weight = attention.call(decoder_outputs,encoder_outputs)\n",
    "    inputs = tf.concat([context_vector,inputs],axis=-1)\n",
    "    decoder_outputs,state_h,state_c = decoder_lstm(inputs,initial_state=states)\n",
    "    outputs = decoder_dense(decoder_dense)\n",
    "    outputs = tf.expand_dims(outputs,1)\n",
    "    all_input.append(outputs)\n",
    "    inputs = outputs\n",
    "    states = [state_h,state_c]\n",
    "\n",
    "decoder_outputs = keras.layers.Lambda(lambda x : keras.layers.concatenate(x,axis=1))(all_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.378806  1.919204 ]\n",
      " [1.37263   1.9150866]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def scaled_dot_product_attention(Q, K, V):\n",
    "    d_k = tf.cast(tf.shape(K)[-1], tf.float32)  # Dimensi key\n",
    "    scores = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(d_k)\n",
    "    attention_weights = tf.nn.softmax(scores, axis=-1)\n",
    "    output = tf.matmul(attention_weights, V)\n",
    "    return output\n",
    "\n",
    "# Contoh input\n",
    "Q = tf.constant([[1.0, 0.5], [0.8, 0.3]], dtype=tf.float32)\n",
    "K = tf.constant([[0.9, 0.7], [0.4, 0.6]], dtype=tf.float32)\n",
    "V = tf.constant([[1.5, 2.0], [1.2, 1.8]], dtype=tf.float32)\n",
    "\n",
    "output = scaled_dot_product_attention(Q, K, V)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttention (keras.layers.Layer):\n",
    "    def __init__ (self,units) :\n",
    "        super(LuongAttention,self).__init__()\n",
    "        self.W1 = Dense(units)\n",
    "        self.W2 = Dense(units)\n",
    "        self.V = Dense(1)\n",
    "    def call(self, query, values):\n",
    "        print('\\n******* Luong Attention  STARTS******')\n",
    "        print('query (decoder hidden state): (batch_size, hidden size) ', query.shape)\n",
    "        print('values (encoder all hidden state): (batch_size, max_len, hidden size) ', values.shape)\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        print('query_with_time_axis:(batch_size, 1, hidden size) ', query_with_time_axis.shape)\n",
    "\n",
    "\n",
    "        values_transposed = tf.transpose(values, perm=[0, 2,1])\n",
    "        print('values_transposed:(batch_size, hidden size, max_len) ', values_transposed.shape)\n",
    "\n",
    "        score = tf.transpose(tf.matmul(query_with_time_axis, values_transposed) , perm=[0, 2, 1])\n",
    "\n",
    "        print('score: (batch_size, max_length, 1) ',score.shape)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        print('context_vector before reduce_sum: (batch_size, max_length, hidden_size) ',context_vector.shape)\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        print('context_vector after reduce_sum: (batch_size, hidden_size) ',context_vector.shape)\n",
    "\n",
    "\n",
    "        print('\\n******* Luong Attention ENDS******')\n",
    "        return context_vector, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Luong Attention  STARTS******\n",
      "query (decoder hidden state): (batch_size, hidden size)  (None, 32)\n",
      "values (encoder all hidden state): (batch_size, max_len, hidden size)  (None, 32)\n",
      "query_with_time_axis:(batch_size, 1, hidden size)  (None, 1, 32)\n",
      "\n",
      "******* Luong Attention  STARTS******\n",
      "query (decoder hidden state): (batch_size, hidden size)  (None, 32)\n",
      "values (encoder all hidden state): (batch_size, max_len, hidden size)  (None, 32)\n",
      "query_with_time_axis:(batch_size, 1, hidden size)  (None, 1, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:1381: UserWarning: Layer 'luong_attention_2' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''Dimension must be 2 but is 3 for '{{node transpose}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32](Placeholder_1, transpose/perm)' with input shapes: [?,32], [3].''\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:391: UserWarning: `build()` was called on layer 'luong_attention_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling LuongAttention.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'luong_attention_2' (of type LuongAttention). Either the `LuongAttention.call()` method is incorrect, or you need to implement the `LuongAttention.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nDimension must be 2 but is 3 for '{{node transpose}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32](Placeholder_1, transpose/perm)' with input shapes: [?,32], [3].\u001b[0m\n\nArguments received by LuongAttention.call():\n  • args=('<KerasTensor shape=(None, 32), dtype=float32, sparse=False, name=keras_tensor_17>', '<KerasTensor shape=(None, 32), dtype=float32, sparse=False, name=keras_tensor_16>')\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m states \u001b[38;5;241m=\u001b[39m encoder_states\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m) :\n\u001b[1;32m---> 18\u001b[0m     context_vector,attention_weight \u001b[38;5;241m=\u001b[39m \u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([context_vector,inputs],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m     decoder_outputs,state_h,state_c \u001b[38;5;241m=\u001b[39m decoder_lstm(inputs,initial_state\u001b[38;5;241m=\u001b[39mstates)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m, in \u001b[0;36mLuongAttention.call\u001b[1;34m(self, query, values)\u001b[0m\n\u001b[0;32m     11\u001b[0m query_with_time_axis \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(query, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery_with_time_axis:(batch_size, 1, hidden size) \u001b[39m\u001b[38;5;124m'\u001b[39m, query_with_time_axis\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 16\u001b[0m values_transposed \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues_transposed:(batch_size, hidden size, max_len) \u001b[39m\u001b[38;5;124m'\u001b[39m, values_transposed\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     19\u001b[0m score \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtranspose(tf\u001b[38;5;241m.\u001b[39mmatmul(query_with_time_axis, values_transposed) , perm\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling LuongAttention.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'luong_attention_2' (of type LuongAttention). Either the `LuongAttention.call()` method is incorrect, or you need to implement the `LuongAttention.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nDimension must be 2 but is 3 for '{{node transpose}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32](Placeholder_1, transpose/perm)' with input shapes: [?,32], [3].\u001b[0m\n\nArguments received by LuongAttention.call():\n  • args=('<KerasTensor shape=(None, 32), dtype=float32, sparse=False, name=keras_tensor_17>', '<KerasTensor shape=(None, 32), dtype=float32, sparse=False, name=keras_tensor_16>')\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "verbose = 0\n",
    "batch_size = 1\n",
    "encoder_inputs = keras.Input(shape=(4,10))\n",
    "encoder_lstm = keras.layers.LSTM(32,return_state=True)\n",
    "encoder_outputs,encoder_state_h,encoder_state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [encoder_state_h,encoder_state_c]\n",
    "attention = LuongAttention(32)\n",
    "decoder_inputs = keras.Input(shape=(1,(4+32)))\n",
    "decoder_lstm = keras.layers.LSTM(32,return_state=True,return_sequences=True)\n",
    "decoder_dense = keras.layers.Dense(10,activation='softmax')\n",
    "\n",
    "all_input = list()\n",
    "inputs = np.zeros((batch_size,1,10))\n",
    "inputs[:,0,0] = 1\n",
    "decoder_outputs = encoder_state_h\n",
    "states = encoder_states\n",
    "for _ in range(4) :\n",
    "    context_vector,attention_weight = attention(decoder_outputs,encoder_outputs)\n",
    "    inputs = tf.concat([context_vector,inputs],axis=-1)\n",
    "    decoder_outputs,state_h,state_c = decoder_lstm(inputs,initial_state=states)\n",
    "    outputs = decoder_dense(decoder_dense)\n",
    "    outputs = tf.expand_dims(outputs,1)\n",
    "    all_input.append(outputs)\n",
    "    inputs = outputs\n",
    "    states = [state_h,state_c]\n",
    "\n",
    "decoder_outputs = keras.layers.Lambda(lambda x : keras.layers.concatenate(x,axis=1))(all_input)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
