{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_speed = np.array([np.random.randint(10,100) / 100 for i in range(1000)])\n",
    "ram_activatiosn = np.array([np.random.randint(10,100) / 100 for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.DataFrame(data={'CPU Speed' : cpu_speed,'Ram Activation' : ram_activatiosn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['Diks'] = np.array([np.random.randint(10,100) / 100 for i in range(1000)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['Network Activity'] = np.array([np.random.randint(10,100) / 100 for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['CPU Status'] = np.array([1 if cpu_speed[i]> 0.7 else 0 for i in range(len(cpu_speed))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['Ram Status'] = np.array([1 if ram_activatiosn[i] > 0.7 else 0 for i in range(len(ram_activatiosn))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['Diks Status'] = np.array([1 if data_set['Diks'][i] > 0.7 else 0 for i in range(0,1000)])\n",
    "data_set['Network Status'] = np.array([1 if data_set['Network Activity'][i] > 0.7 else 0 for i in range(0,1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conenct = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    user = 'root',\n",
    "    password = 'airin123',\n",
    "    database = 'knight_bot'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conenct.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_set.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_insert = [tuple(row) for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 0.93, 0.75, 0.3, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.93, 0.74, 0.16, 0.94, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.37, 0.81, 0.97, 0.27, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.64, 0.21, 0.82, 0.24, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.22, 0.59, 0.89, 0.39, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.62, 0.1, 0.28, 0.81, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.6, 0.91, 0.83, 0.9, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.52, 0.35, 0.14, 0.73, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.87, 0.21, 0.36, 0.24, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.58, 0.66, 0.16, 0.45, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.19, 0.41, 0.12, 0.51, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.62, 0.3, 0.48, 0.78, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.68, 0.48, 0.67, 0.52, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.79, 0.79, 0.95, 0.13, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.59, 0.72, 0.67, 0.26, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.34, 0.18, 0.76, 0.65, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.29, 0.88, 0.79, 0.2, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.38, 0.97, 0.26, 0.87, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.33, 0.68, 0.77, 0.86, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.69, 0.53, 0.28, 0.2, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.94, 0.81, 0.49, 0.92, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.92, 0.22, 0.28, 0.11, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.62, 0.62, 0.47, 0.64, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.95, 0.11, 0.35, 0.99, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.77, 0.42, 0.75, 0.94, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.39, 0.45, 0.94, 0.88, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.94, 0.51, 0.14, 0.15, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.75, 0.1, 0.83, 0.87, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.22, 0.66, 0.52, 0.29, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.19, 0.58, 0.96, 0.71, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.76, 0.61, 0.58, 0.64, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.54, 0.81, 0.86, 0.99, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.76, 0.78, 0.27, 0.44, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.19, 0.36, 0.4, 0.6, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.19, 0.84, 0.24, 0.81, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.18, 0.66, 0.93, 0.49, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.86, 0.47, 0.38, 0.99, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.76, 0.84, 0.68, 0.99, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.17, 0.64, 0.1, 0.57, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.18, 0.1, 0.89, 0.42, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.83, 0.42, 0.61, 0.84, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.59, 0.22, 0.95, 0.69, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.22, 0.86, 0.45, 0.88, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.66, 0.4, 0.4, 0.22, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.44, 0.43, 0.46, 0.87, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.92, 0.96, 0.98, 0.12, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.71, 0.32, 0.46, 0.74, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.25, 0.81, 0.24, 0.4, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.95, 0.85, 0.83, 0.68, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.48, 0.46, 0.29, 0.3, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.88, 0.14, 0.91, 0.73, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.96, 0.35, 0.26, 0.39, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.89, 0.99, 0.2, 0.28, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.64, 0.68, 0.63, 0.59, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.84, 0.89, 0.4, 0.31, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.17, 0.39, 0.92, 0.45, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.15, 0.35, 0.26, 0.28, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.5, 0.98, 0.7, 0.99, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.71, 0.31, 0.8, 0.74, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.26, 0.9, 0.79, 0.54, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.75, 0.1, 0.53, 0.99, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.25, 0.21, 0.7, 0.45, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.97, 0.1, 0.62, 0.18, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.88, 0.87, 0.74, 0.79, 1.0, 1.0, 1.0, 1.0),\n",
       " (0.81, 0.34, 0.92, 0.64, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.22, 0.97, 0.92, 0.96, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.13, 0.88, 0.73, 0.44, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.66, 0.62, 0.98, 0.34, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.36, 0.56, 0.46, 0.18, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.39, 0.84, 0.71, 0.89, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.3, 0.65, 0.54, 0.41, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.89, 0.25, 0.49, 0.68, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.13, 0.76, 0.9, 0.92, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.27, 0.86, 0.41, 0.45, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.67, 0.91, 0.16, 0.98, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.24, 0.55, 0.21, 0.99, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.15, 0.71, 0.8, 0.9, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.68, 0.82, 0.25, 0.51, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.9, 0.39, 0.36, 0.53, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.77, 0.61, 0.87, 0.22, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.75, 0.84, 0.9, 0.95, 1.0, 1.0, 1.0, 1.0),\n",
       " (0.36, 0.97, 0.41, 0.74, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.29, 0.76, 0.2, 0.26, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.28, 0.23, 0.34, 0.7, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.68, 0.3, 0.85, 0.2, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.33, 0.57, 0.56, 0.85, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.45, 0.25, 0.87, 0.62, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.79, 0.68, 0.79, 0.52, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.34, 0.3, 0.4, 0.22, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.99, 0.76, 0.9, 0.32, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.18, 0.52, 0.65, 0.42, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.17, 0.54, 0.5, 0.16, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.37, 0.45, 0.51, 0.38, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.43, 0.65, 0.81, 0.61, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.75, 0.68, 0.95, 0.13, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.65, 0.6, 0.71, 0.16, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.72, 0.2, 0.63, 0.48, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.76, 0.7, 0.39, 0.73, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.42, 0.97, 0.5, 0.58, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.42, 0.69, 0.85, 0.78, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.99, 0.27, 0.66, 0.98, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.34, 0.85, 0.13, 0.11, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.18, 0.27, 0.65, 0.34, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.65, 0.27, 0.45, 0.63, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.67, 0.35, 0.64, 0.21, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.66, 0.14, 0.35, 0.11, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.49, 0.52, 0.99, 0.5, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.88, 0.57, 0.67, 0.4, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.42, 0.85, 0.11, 0.85, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.93, 0.2, 0.55, 0.6, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.65, 0.79, 0.31, 0.11, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.76, 0.75, 0.1, 0.28, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.11, 0.74, 0.79, 0.75, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.64, 0.43, 0.7, 0.75, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.96, 0.73, 0.84, 0.8, 1.0, 1.0, 1.0, 1.0),\n",
       " (0.12, 0.32, 0.39, 0.65, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.25, 0.7, 0.61, 0.15, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.3, 0.61, 0.16, 0.72, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.52, 0.2, 0.87, 0.73, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.29, 0.12, 0.38, 0.55, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.82, 0.51, 0.85, 0.16, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.47, 0.3, 0.96, 0.66, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.63, 0.27, 0.65, 0.48, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.62, 0.13, 0.81, 0.19, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.94, 0.95, 0.13, 0.49, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.93, 0.26, 0.54, 0.44, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.97, 0.3, 0.93, 0.66, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.68, 0.88, 0.15, 0.23, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.48, 0.81, 0.84, 0.98, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.43, 0.54, 0.82, 0.99, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.7, 0.64, 0.34, 0.58, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.12, 0.94, 0.65, 0.71, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.6, 0.27, 0.58, 0.29, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.69, 0.6, 0.27, 0.75, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.31, 0.54, 0.24, 0.62, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.75, 0.43, 0.12, 0.83, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.2, 0.11, 0.19, 0.27, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.69, 0.65, 0.24, 0.55, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.34, 0.79, 0.41, 0.57, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.74, 0.27, 0.98, 0.5, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.75, 0.58, 0.34, 0.18, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.55, 0.64, 0.12, 0.63, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.6, 0.44, 0.69, 0.58, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.35, 0.72, 0.3, 0.52, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.96, 0.89, 0.15, 0.93, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.31, 0.8, 0.46, 0.33, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.9, 0.67, 0.55, 0.82, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.9, 0.86, 0.48, 0.77, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.46, 0.18, 0.74, 0.46, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.5, 0.39, 0.95, 0.44, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.36, 0.18, 0.36, 0.72, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.47, 0.84, 0.49, 0.56, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.41, 0.78, 0.86, 0.54, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.55, 0.68, 0.87, 0.31, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.4, 0.97, 0.98, 0.43, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.31, 0.18, 0.6, 0.62, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.54, 0.18, 0.6, 0.97, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.28, 0.83, 0.82, 0.55, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.16, 0.21, 0.51, 0.44, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.41, 0.37, 0.52, 0.85, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.1, 0.6, 0.25, 0.93, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.97, 0.74, 0.47, 0.94, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.64, 0.14, 0.88, 0.93, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.19, 0.53, 0.44, 0.66, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.24, 0.19, 0.17, 0.76, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.22, 0.62, 0.43, 0.16, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.17, 0.45, 0.43, 0.42, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.98, 0.51, 0.37, 0.97, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.37, 0.83, 0.35, 0.63, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.86, 0.48, 0.6, 0.44, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.78, 0.54, 0.13, 0.72, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.95, 0.82, 0.43, 0.53, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.46, 0.51, 0.42, 0.76, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.26, 0.92, 0.8, 0.23, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.5, 0.52, 0.3, 0.86, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.87, 0.67, 0.42, 0.52, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.17, 0.45, 0.6, 0.6, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.91, 0.99, 0.16, 0.69, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.69, 0.94, 0.39, 0.46, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.33, 0.56, 0.8, 0.95, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.56, 0.24, 0.83, 0.67, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.32, 0.78, 0.4, 0.35, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.75, 0.64, 0.65, 0.59, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.57, 0.31, 0.44, 0.45, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.72, 0.6, 0.54, 0.67, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.14, 0.87, 0.81, 0.93, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.19, 0.75, 0.86, 0.85, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.57, 0.35, 0.62, 0.51, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.79, 0.72, 0.81, 0.58, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.72, 0.79, 0.6, 0.42, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.32, 0.34, 0.28, 0.61, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.67, 0.73, 0.66, 0.81, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.42, 0.59, 0.7, 0.7, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.44, 0.87, 0.84, 0.78, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.63, 0.72, 0.46, 0.25, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.58, 0.73, 0.99, 0.64, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.14, 0.74, 0.17, 0.3, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.69, 0.99, 0.87, 0.87, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.68, 0.23, 0.32, 0.76, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.6, 0.44, 0.29, 0.19, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.53, 0.33, 0.12, 0.11, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.72, 0.63, 0.16, 0.47, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.51, 0.81, 0.37, 0.67, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.25, 0.83, 0.49, 0.42, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.6, 0.35, 0.76, 0.1, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.45, 0.43, 0.26, 0.62, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.93, 0.3, 0.41, 0.93, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.1, 0.58, 0.3, 0.88, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.25, 0.53, 0.47, 0.32, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.76, 0.88, 0.33, 0.6, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.1, 0.54, 0.39, 0.18, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.66, 0.74, 0.58, 0.38, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.23, 0.88, 0.78, 0.56, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.32, 0.79, 0.73, 0.88, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.97, 0.65, 0.92, 0.12, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.81, 0.99, 0.4, 0.95, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.32, 0.48, 0.61, 0.44, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.29, 0.29, 0.29, 0.26, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.56, 0.1, 0.41, 0.99, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.61, 0.11, 0.85, 0.3, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.31, 0.81, 0.82, 0.7, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.53, 0.84, 0.4, 0.24, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.73, 0.58, 0.11, 0.85, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.44, 0.84, 0.75, 0.56, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.73, 0.19, 0.72, 0.66, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.89, 0.45, 0.71, 0.6, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.15, 0.64, 0.44, 0.18, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.25, 0.16, 0.76, 0.64, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.12, 0.12, 0.71, 0.22, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.69, 0.62, 0.25, 0.8, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.84, 0.14, 0.41, 0.9, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.37, 0.79, 0.66, 0.31, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.28, 0.58, 0.27, 0.43, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.82, 0.65, 0.77, 0.44, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.94, 0.76, 0.87, 0.88, 1.0, 1.0, 1.0, 1.0),\n",
       " (0.47, 0.91, 0.15, 0.62, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.45, 0.25, 0.6, 0.73, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.53, 0.77, 0.68, 0.42, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.27, 0.81, 0.59, 0.1, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.55, 0.36, 0.32, 0.8, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.71, 0.25, 0.85, 0.37, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.14, 0.23, 0.79, 0.46, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.86, 0.84, 0.43, 0.45, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.75, 0.4, 0.91, 0.19, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.62, 0.55, 0.84, 0.21, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.26, 0.98, 0.82, 0.56, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.68, 0.94, 0.94, 0.23, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.6, 0.63, 0.71, 0.15, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.7, 0.75, 0.81, 0.91, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.87, 0.22, 0.94, 0.4, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.26, 0.79, 0.57, 0.76, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.13, 0.91, 0.41, 0.88, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.28, 0.11, 0.15, 0.46, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.47, 0.29, 0.57, 0.17, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.1, 0.65, 0.58, 0.58, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.12, 0.96, 0.1, 0.11, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.21, 0.3, 0.25, 0.15, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.77, 0.19, 0.76, 0.53, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.47, 0.12, 0.26, 0.58, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.96, 0.34, 0.54, 0.63, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.77, 0.15, 0.19, 0.23, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.94, 0.99, 0.45, 0.87, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.32, 0.54, 0.24, 0.99, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.56, 0.72, 0.1, 0.56, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.58, 0.89, 0.56, 0.32, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.55, 0.34, 0.59, 0.81, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.44, 0.38, 0.49, 0.14, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.99, 0.36, 0.3, 0.52, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.1, 0.64, 0.96, 0.73, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.28, 0.32, 0.85, 0.81, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.16, 0.81, 0.68, 0.35, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.87, 0.69, 0.42, 0.72, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.42, 0.6, 0.36, 0.21, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.27, 0.95, 0.1, 0.71, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.6, 0.56, 0.85, 0.17, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.61, 0.92, 0.87, 0.94, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.94, 0.26, 0.84, 0.78, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.79, 0.63, 0.92, 0.2, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.21, 0.17, 0.14, 0.21, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.48, 0.98, 0.46, 0.94, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.7, 0.46, 0.5, 0.6, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.72, 0.47, 0.25, 0.85, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.8, 0.42, 0.53, 0.39, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.28, 0.21, 0.67, 0.56, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.54, 0.86, 0.85, 0.1, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.34, 0.17, 0.42, 0.28, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.86, 0.23, 0.98, 0.55, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.54, 0.47, 0.3, 0.3, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.91, 0.46, 0.79, 0.34, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.37, 0.5, 0.45, 0.48, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.4, 0.28, 0.69, 0.95, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.27, 0.58, 0.81, 0.72, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.34, 0.66, 0.94, 0.54, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.54, 0.39, 0.21, 0.86, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.62, 0.98, 0.96, 0.76, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.57, 0.69, 0.3, 0.95, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.23, 0.51, 0.39, 0.21, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.72, 0.84, 0.18, 0.88, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.98, 0.28, 0.63, 0.26, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.25, 0.42, 0.94, 0.58, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.87, 0.29, 0.49, 0.81, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.54, 0.83, 0.81, 0.72, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.38, 0.55, 0.68, 0.6, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.63, 0.73, 0.49, 0.96, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.6, 0.11, 0.82, 0.84, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.23, 0.94, 0.51, 0.87, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.23, 0.17, 0.79, 0.41, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.11, 0.33, 0.57, 0.1, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.93, 0.52, 0.81, 0.68, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.46, 0.58, 0.12, 0.25, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.79, 0.79, 0.69, 0.65, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.42, 0.54, 0.91, 0.2, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.58, 0.64, 0.32, 0.82, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.62, 0.9, 0.97, 0.31, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.98, 0.75, 0.64, 0.43, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.53, 0.97, 0.16, 0.58, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.48, 0.88, 0.6, 0.34, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.95, 0.97, 0.37, 0.86, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.45, 0.46, 0.56, 0.33, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.39, 0.53, 0.83, 0.99, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.58, 0.37, 0.81, 0.86, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.5, 0.45, 0.77, 0.31, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.28, 0.64, 0.98, 0.24, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.25, 0.89, 0.9, 0.28, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.79, 0.53, 0.7, 0.28, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.3, 0.27, 0.31, 0.89, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.85, 0.19, 0.55, 0.79, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.68, 0.16, 0.63, 0.33, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.19, 0.75, 0.99, 0.71, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.39, 0.86, 0.84, 0.73, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.55, 0.7, 0.42, 0.47, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.75, 0.82, 0.22, 0.52, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.88, 0.27, 0.94, 0.71, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.88, 0.36, 0.5, 0.15, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.18, 0.9, 0.85, 0.31, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.77, 0.5, 0.27, 0.68, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.39, 0.95, 0.15, 0.17, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.73, 0.98, 0.66, 0.89, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.94, 0.36, 0.13, 0.21, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.25, 0.68, 0.67, 0.98, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.54, 0.94, 0.32, 0.88, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.57, 0.25, 0.76, 0.97, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.23, 0.57, 0.95, 0.74, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.69, 0.17, 0.76, 0.43, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.9, 0.79, 0.89, 0.88, 1.0, 1.0, 1.0, 1.0),\n",
       " (0.8, 0.75, 0.12, 0.95, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.52, 0.22, 0.4, 0.55, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.87, 0.65, 0.41, 0.35, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.37, 0.43, 0.19, 0.39, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.64, 0.46, 0.11, 0.24, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.31, 0.53, 0.26, 0.19, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.81, 0.92, 0.29, 0.75, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.97, 0.82, 0.36, 0.24, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.16, 0.91, 0.58, 0.77, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.94, 0.89, 0.98, 0.81, 1.0, 1.0, 1.0, 1.0),\n",
       " (0.74, 0.25, 0.95, 0.32, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.46, 0.3, 0.91, 0.41, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.7, 0.37, 0.36, 0.71, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.27, 0.75, 0.81, 0.75, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.16, 0.86, 0.68, 0.5, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.74, 0.27, 0.43, 0.75, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.68, 0.8, 0.62, 0.68, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.22, 0.3, 0.84, 0.58, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.37, 0.39, 0.13, 0.11, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.84, 0.38, 0.78, 0.29, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.64, 0.76, 0.57, 0.51, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.22, 0.88, 0.79, 0.71, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.94, 0.26, 0.97, 0.3, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.42, 0.15, 0.36, 0.29, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.39, 0.5, 0.76, 0.15, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.42, 0.21, 0.6, 0.44, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.52, 0.63, 0.21, 0.74, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.19, 0.61, 0.33, 0.58, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.27, 0.14, 0.17, 0.35, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.3, 0.98, 0.41, 0.11, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.9, 0.16, 0.31, 0.75, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.84, 0.2, 0.66, 0.78, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.16, 0.83, 0.8, 0.51, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.1, 0.7, 0.45, 0.36, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.78, 0.71, 0.39, 0.79, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.31, 0.75, 0.15, 0.87, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.77, 0.42, 0.23, 0.34, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.87, 0.37, 0.17, 0.76, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.69, 0.65, 0.6, 0.78, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.51, 0.64, 0.12, 0.93, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.26, 0.18, 0.26, 0.35, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.67, 0.9, 0.95, 0.33, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.84, 0.59, 0.18, 0.88, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.57, 0.68, 0.73, 0.97, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.72, 0.36, 0.58, 0.32, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.92, 0.89, 0.48, 0.77, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.95, 0.31, 0.12, 0.15, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.49, 0.19, 0.75, 0.45, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.89, 0.16, 0.62, 0.35, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.31, 0.41, 0.67, 0.5, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.42, 0.37, 0.6, 0.35, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.86, 0.34, 0.35, 0.45, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.42, 0.48, 0.32, 0.29, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.4, 0.69, 0.26, 0.56, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.63, 0.14, 0.13, 0.65, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.97, 0.95, 0.5, 0.4, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.18, 0.11, 0.46, 0.53, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.17, 0.35, 0.99, 0.33, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.82, 0.21, 0.39, 0.23, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.92, 0.46, 0.66, 0.67, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.22, 0.59, 0.5, 0.62, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.26, 0.32, 0.28, 0.29, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.87, 0.22, 0.93, 0.25, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.56, 0.81, 0.59, 0.48, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.73, 0.52, 0.77, 0.62, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.69, 0.87, 0.18, 0.3, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.86, 0.1, 0.29, 0.73, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.12, 0.2, 0.22, 0.27, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.36, 0.59, 0.39, 0.54, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.58, 0.15, 0.35, 0.35, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.88, 0.95, 0.15, 0.53, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.3, 0.45, 0.63, 0.95, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.14, 0.5, 0.16, 0.32, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.61, 0.45, 0.66, 0.12, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.15, 0.58, 0.28, 0.95, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.85, 0.6, 0.49, 0.8, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.1, 0.46, 0.44, 0.61, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.96, 0.9, 0.66, 0.68, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.93, 0.33, 0.12, 0.31, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.11, 0.6, 0.48, 0.52, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.83, 0.46, 0.1, 0.94, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.31, 0.6, 0.13, 0.17, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.14, 0.64, 0.44, 0.97, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.39, 0.33, 0.15, 0.79, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.6, 0.86, 0.57, 0.41, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.88, 0.8, 0.38, 0.86, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.24, 0.34, 0.52, 0.35, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.39, 0.34, 0.25, 0.13, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.79, 0.2, 0.95, 0.96, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.95, 0.68, 0.68, 0.61, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.92, 0.25, 0.31, 0.63, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.74, 0.83, 0.15, 0.85, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.82, 0.23, 0.66, 0.15, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.89, 0.15, 0.14, 0.44, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.41, 0.71, 0.65, 0.31, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.66, 0.45, 0.44, 0.16, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.17, 0.85, 0.82, 0.17, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.19, 0.17, 0.96, 0.84, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.71, 0.1, 0.93, 0.7, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.19, 0.81, 0.85, 0.48, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.96, 0.72, 0.74, 0.93, 1.0, 1.0, 1.0, 1.0),\n",
       " (0.75, 0.1, 0.99, 0.95, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.44, 0.35, 0.63, 0.69, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.45, 0.1, 0.23, 0.95, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.38, 0.3, 0.98, 0.35, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.42, 0.75, 0.11, 0.72, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.63, 0.31, 0.7, 0.27, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.12, 0.15, 0.66, 0.57, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.66, 0.96, 0.36, 0.94, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.4, 0.94, 0.34, 0.94, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.83, 0.34, 0.76, 0.93, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.77, 0.32, 0.39, 0.38, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.26, 0.99, 0.65, 0.23, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.87, 0.93, 0.45, 0.95, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.57, 0.7, 0.86, 0.79, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.22, 0.31, 0.15, 0.99, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.62, 0.81, 0.89, 0.93, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.37, 0.51, 0.37, 0.32, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.67, 0.32, 0.71, 0.34, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.38, 0.67, 0.9, 0.42, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.81, 0.79, 0.89, 0.67, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.66, 0.15, 0.54, 0.67, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.71, 0.52, 0.44, 0.87, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.26, 0.41, 0.33, 0.85, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.33, 0.77, 0.37, 0.4, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.86, 0.17, 0.99, 0.96, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.81, 0.25, 0.19, 0.56, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.55, 0.36, 0.82, 0.15, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.85, 0.93, 0.88, 0.8, 1.0, 1.0, 1.0, 1.0),\n",
       " (0.84, 0.33, 0.43, 0.89, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.68, 0.14, 0.27, 0.86, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.15, 0.44, 0.56, 0.17, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.67, 0.22, 0.64, 0.5, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.68, 0.84, 0.82, 0.13, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.89, 0.28, 0.14, 0.84, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.81, 0.82, 0.55, 0.16, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.91, 0.27, 0.12, 0.81, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.68, 0.78, 0.43, 0.93, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.97, 0.76, 0.98, 0.1, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.46, 0.73, 0.2, 0.31, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.66, 0.11, 0.13, 0.13, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.31, 0.84, 0.53, 0.13, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.51, 0.35, 0.58, 0.91, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.67, 0.48, 0.22, 0.26, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.14, 0.61, 0.46, 0.8, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.83, 0.12, 0.16, 0.71, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.7, 0.27, 0.37, 0.55, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.21, 0.46, 0.3, 0.24, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.44, 0.52, 0.75, 0.55, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.52, 0.43, 0.68, 0.38, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.92, 0.44, 0.44, 0.73, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.38, 0.98, 0.63, 0.6, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.34, 0.78, 0.72, 0.89, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.56, 0.21, 0.73, 0.56, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.46, 0.81, 0.79, 0.66, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.69, 0.41, 0.13, 0.29, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.55, 0.6, 0.3, 0.55, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.95, 0.99, 0.23, 0.22, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.8, 0.54, 0.19, 0.39, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.71, 0.14, 0.84, 0.46, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.61, 0.1, 0.64, 0.31, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.22, 0.3, 0.62, 0.55, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.15, 0.74, 0.82, 0.46, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.57, 0.52, 0.18, 0.17, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.31, 0.39, 0.25, 0.24, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.11, 0.74, 0.6, 0.71, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.71, 0.53, 0.15, 0.34, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.42, 0.53, 0.53, 0.66, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.37, 0.25, 0.28, 0.38, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.57, 0.56, 0.14, 0.1, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.76, 0.19, 0.12, 0.42, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.21, 0.97, 0.51, 0.66, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.9, 0.72, 0.18, 0.64, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.43, 0.4, 0.66, 0.25, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.72, 0.17, 0.62, 0.99, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.86, 0.65, 0.97, 0.21, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.12, 0.13, 0.46, 0.23, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.6, 0.2, 0.28, 0.83, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.16, 0.59, 0.93, 0.62, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.1, 0.18, 0.42, 0.63, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.22, 0.28, 0.5, 0.16, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.15, 0.48, 0.59, 0.14, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.31, 0.79, 0.68, 0.81, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.79, 0.72, 0.27, 0.23, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.98, 0.72, 0.86, 0.3, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.21, 0.57, 0.43, 0.36, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.35, 0.69, 0.99, 0.73, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.83, 0.8, 0.63, 0.59, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.41, 0.11, 0.56, 0.23, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.93, 0.87, 0.83, 0.81, 1.0, 1.0, 1.0, 1.0),\n",
       " (0.63, 0.23, 0.54, 0.33, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.23, 0.2, 0.21, 0.23, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.65, 0.67, 0.21, 0.52, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.17, 0.39, 0.34, 0.97, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.85, 0.4, 0.11, 0.18, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.79, 0.66, 0.89, 0.17, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.32, 0.64, 0.56, 0.56, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.95, 0.4, 0.49, 0.17, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.91, 0.56, 0.79, 0.69, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.29, 0.11, 0.2, 0.3, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.49, 0.13, 0.39, 0.65, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.96, 0.3, 0.76, 0.95, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.25, 0.75, 0.68, 0.41, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.87, 0.75, 0.96, 0.16, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.47, 0.85, 0.9, 0.79, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.24, 0.58, 0.65, 0.24, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.37, 0.35, 0.73, 0.63, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.93, 0.13, 0.2, 0.74, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.57, 0.46, 0.19, 0.46, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.38, 0.37, 0.43, 0.14, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.75, 0.42, 0.47, 0.52, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.63, 0.49, 0.75, 0.16, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.84, 0.35, 0.95, 0.9, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.67, 0.93, 0.88, 0.8, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.15, 0.88, 0.91, 0.86, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.97, 0.86, 0.17, 0.31, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.24, 0.27, 0.54, 0.79, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.15, 0.67, 0.92, 0.99, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.48, 0.45, 0.75, 0.17, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.41, 0.52, 0.13, 0.72, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.52, 0.62, 0.91, 0.41, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.92, 0.97, 0.28, 0.11, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.57, 0.58, 0.96, 0.68, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.3, 0.32, 0.49, 0.71, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.54, 0.19, 0.37, 0.51, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.62, 0.87, 0.12, 0.98, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.75, 0.57, 0.37, 0.36, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.52, 0.89, 0.19, 0.1, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.57, 0.2, 0.55, 0.24, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.58, 0.45, 0.63, 0.37, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.92, 0.41, 0.92, 0.34, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.12, 0.84, 0.14, 0.73, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.48, 0.94, 0.2, 0.65, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.68, 0.46, 0.64, 0.16, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.3, 0.62, 0.38, 0.43, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.93, 0.67, 0.54, 0.19, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.8, 0.91, 0.45, 0.38, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.18, 0.77, 0.31, 0.12, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.72, 0.81, 0.68, 0.87, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.56, 0.25, 0.3, 0.87, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.47, 0.22, 0.93, 0.87, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.29, 0.38, 0.88, 0.85, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.4, 0.34, 0.72, 0.22, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.43, 0.51, 0.7, 0.4, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.77, 0.94, 0.66, 0.43, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.88, 0.74, 0.32, 0.98, 1.0, 1.0, 0.0, 1.0),\n",
       " (0.96, 0.93, 0.97, 0.35, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.25, 0.66, 0.13, 0.61, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.65, 0.39, 0.76, 0.53, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.41, 0.93, 0.54, 0.7, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.5, 0.4, 0.91, 0.17, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.16, 0.55, 0.45, 0.65, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.27, 0.95, 0.58, 0.32, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.96, 0.21, 0.93, 0.18, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.49, 0.62, 0.56, 0.41, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.94, 0.5, 0.74, 0.37, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.93, 0.54, 0.96, 0.32, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.45, 0.18, 0.72, 0.38, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.7, 0.65, 0.69, 0.97, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.32, 0.25, 0.23, 0.92, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.44, 0.59, 0.23, 0.33, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.73, 0.52, 0.84, 0.15, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.93, 0.21, 0.86, 0.98, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.41, 0.23, 0.53, 0.99, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.31, 0.65, 0.35, 0.38, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.8, 0.96, 0.23, 0.14, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.45, 0.1, 0.57, 0.59, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.79, 0.38, 0.65, 0.95, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.87, 0.41, 0.87, 0.91, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.97, 0.6, 0.36, 0.65, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.47, 0.35, 0.71, 0.66, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.76, 0.74, 0.52, 0.56, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.8, 0.96, 0.24, 0.43, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.85, 0.43, 0.45, 0.74, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.94, 0.94, 0.35, 0.54, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.61, 0.96, 0.68, 0.16, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.13, 0.82, 0.45, 0.43, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.15, 0.25, 0.21, 0.17, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.1, 0.27, 0.14, 0.76, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.61, 0.17, 0.98, 0.95, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.37, 0.77, 0.69, 0.53, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.15, 0.4, 0.95, 0.8, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.76, 0.94, 0.8, 0.94, 1.0, 1.0, 1.0, 1.0),\n",
       " (0.75, 0.61, 0.67, 0.84, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.52, 0.66, 0.32, 0.23, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.3, 0.84, 0.78, 0.4, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.65, 0.79, 0.35, 0.55, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.74, 0.96, 0.96, 0.17, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.12, 0.37, 0.74, 0.26, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.93, 0.85, 0.85, 0.28, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.34, 0.35, 0.98, 0.66, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.95, 0.17, 0.57, 0.21, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.45, 0.64, 0.54, 0.69, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.66, 0.32, 0.67, 0.17, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.73, 0.31, 0.56, 0.63, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.23, 0.23, 0.11, 0.42, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.83, 0.36, 0.88, 0.63, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.8, 0.27, 0.75, 0.6, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.68, 0.73, 0.16, 0.64, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.96, 0.23, 0.51, 0.49, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.78, 0.67, 0.7, 0.31, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.41, 0.91, 0.67, 0.66, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.82, 0.67, 0.52, 0.4, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.43, 0.91, 0.31, 0.62, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.53, 0.24, 0.99, 0.65, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.12, 0.55, 0.85, 0.22, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.85, 0.67, 0.38, 0.44, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.39, 0.81, 0.39, 0.73, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.16, 0.74, 0.83, 0.22, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.99, 0.24, 0.97, 0.19, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.77, 0.75, 0.58, 0.27, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.95, 0.21, 0.62, 0.83, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.48, 0.24, 0.78, 0.97, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.74, 0.76, 0.57, 0.37, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.78, 0.16, 0.15, 0.16, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.32, 0.46, 0.34, 0.87, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.78, 0.25, 0.98, 0.54, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.76, 0.72, 0.36, 0.22, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.79, 0.56, 0.26, 0.46, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.34, 0.83, 0.94, 0.13, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.92, 0.67, 0.1, 0.67, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.7, 0.61, 0.53, 0.93, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.74, 0.54, 0.86, 0.8, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.23, 0.33, 0.98, 0.25, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.39, 0.93, 0.43, 0.69, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.47, 0.37, 0.45, 0.49, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.18, 0.88, 0.24, 0.92, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.22, 0.95, 0.49, 0.74, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.76, 0.13, 0.81, 0.26, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.99, 0.41, 0.29, 0.39, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.81, 0.47, 0.22, 0.86, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.93, 0.96, 0.75, 0.64, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.99, 0.19, 0.76, 0.14, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.7, 0.37, 0.17, 0.3, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.9, 0.39, 0.55, 0.38, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.85, 0.24, 0.58, 0.92, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.59, 0.37, 0.52, 0.19, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.3, 0.27, 0.35, 0.38, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.13, 0.24, 0.28, 0.72, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.89, 0.38, 0.38, 0.83, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.74, 0.28, 0.33, 0.58, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.21, 0.74, 0.68, 0.63, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.95, 0.16, 0.4, 0.64, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.63, 0.74, 0.68, 0.89, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.11, 0.57, 0.92, 0.12, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.25, 0.51, 0.98, 0.28, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.52, 0.64, 0.38, 0.44, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.45, 0.42, 0.22, 0.68, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.91, 0.79, 0.7, 0.57, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.98, 0.63, 0.33, 0.9, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.14, 0.59, 0.96, 0.32, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.13, 0.64, 0.45, 0.34, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.29, 0.91, 0.2, 0.65, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.26, 0.29, 0.21, 0.43, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.23, 0.48, 0.39, 0.44, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.66, 0.2, 0.1, 0.86, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.6, 0.13, 0.17, 0.16, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.28, 0.46, 0.3, 0.67, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.63, 0.32, 0.18, 0.31, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.18, 0.25, 0.1, 0.59, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.97, 0.25, 0.34, 0.26, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.87, 0.3, 0.57, 0.76, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.66, 0.79, 0.25, 0.95, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.21, 0.55, 0.79, 0.86, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.91, 0.71, 0.91, 0.34, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.25, 0.58, 0.35, 0.19, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.82, 0.54, 0.39, 0.48, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.87, 0.5, 0.58, 0.26, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.31, 0.32, 0.32, 0.24, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.23, 0.19, 0.1, 0.58, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.41, 0.68, 0.37, 0.41, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.67, 0.33, 0.87, 0.78, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.17, 0.87, 0.22, 0.32, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.45, 0.67, 0.22, 0.35, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.76, 0.64, 0.83, 0.64, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.37, 0.36, 0.21, 0.53, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.74, 0.34, 0.14, 0.52, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.89, 0.94, 0.1, 0.2, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.95, 0.2, 0.37, 0.3, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.59, 0.4, 0.32, 0.63, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.29, 0.77, 0.57, 0.7, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.87, 0.29, 0.89, 0.68, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.38, 0.64, 0.26, 0.91, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.33, 0.46, 0.6, 0.65, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.5, 0.3, 0.19, 0.63, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.9, 0.45, 0.57, 0.87, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.29, 0.9, 0.47, 0.5, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.37, 0.25, 0.82, 0.98, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.76, 0.83, 0.95, 0.12, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.76, 0.29, 0.49, 0.89, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.24, 0.81, 0.24, 0.78, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.13, 0.53, 0.66, 0.68, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.34, 0.57, 0.4, 0.21, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.32, 0.96, 0.89, 0.91, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.28, 0.78, 0.85, 0.14, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.11, 0.21, 0.77, 0.17, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.36, 0.76, 0.99, 0.24, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.56, 0.85, 0.9, 0.83, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.35, 0.79, 0.18, 0.6, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.89, 0.56, 0.97, 0.38, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.44, 0.91, 0.65, 0.29, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.88, 0.49, 0.96, 0.51, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.21, 0.35, 0.42, 0.35, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.11, 0.64, 0.6, 0.98, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.93, 0.2, 0.49, 0.59, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.63, 0.41, 0.1, 0.53, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.87, 0.61, 0.9, 0.97, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.91, 0.11, 0.72, 0.64, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.11, 0.26, 0.26, 0.74, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.35, 0.26, 0.3, 0.6, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.51, 0.16, 0.41, 0.62, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.43, 0.35, 0.74, 0.93, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.23, 0.85, 0.12, 0.61, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.27, 0.53, 0.9, 0.52, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.14, 0.67, 0.18, 0.29, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.9, 0.31, 0.67, 0.14, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.39, 0.65, 0.33, 0.31, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.47, 0.36, 0.56, 0.88, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.85, 0.25, 0.9, 0.99, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.24, 0.41, 0.2, 0.69, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.74, 0.13, 0.16, 0.38, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.19, 0.31, 0.12, 0.29, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.28, 0.89, 0.49, 0.93, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.37, 0.81, 0.4, 0.8, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.62, 0.7, 0.58, 0.19, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.26, 0.84, 0.88, 0.84, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.63, 0.32, 0.45, 0.67, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.12, 0.3, 0.67, 0.6, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.85, 0.56, 0.17, 0.83, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.2, 0.65, 0.33, 0.2, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.36, 0.72, 0.79, 0.51, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.74, 0.43, 0.64, 0.99, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.45, 0.12, 0.63, 0.44, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.7, 0.4, 0.91, 0.48, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.87, 0.43, 0.76, 0.41, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.77, 0.64, 0.8, 0.73, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.33, 0.95, 0.67, 0.33, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.62, 0.87, 0.25, 0.88, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.31, 0.44, 0.75, 0.32, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.99, 0.74, 0.87, 0.33, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.4, 0.71, 0.76, 0.15, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.98, 0.67, 0.2, 0.37, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.23, 0.61, 0.97, 0.7, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.73, 0.52, 0.54, 0.25, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.49, 0.61, 0.5, 0.92, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.93, 0.12, 0.92, 0.49, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.84, 0.43, 0.89, 0.97, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.5, 0.71, 0.53, 0.22, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.4, 0.35, 0.39, 0.86, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.62, 0.82, 0.17, 0.58, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.18, 0.3, 0.53, 0.35, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.37, 0.42, 0.96, 0.51, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.64, 0.56, 0.21, 0.51, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.12, 0.18, 0.2, 0.42, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.2, 0.47, 0.95, 0.32, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.43, 0.22, 0.37, 0.24, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.73, 0.46, 0.54, 0.96, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.4, 0.57, 0.8, 0.77, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.99, 0.6, 0.56, 0.72, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.92, 0.83, 0.95, 0.39, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.76, 0.31, 0.9, 0.96, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.73, 0.5, 0.36, 0.14, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.54, 0.29, 0.7, 0.81, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.34, 0.47, 0.86, 0.51, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.35, 0.51, 0.48, 0.86, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.19, 0.68, 0.51, 0.64, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.95, 0.56, 0.67, 0.15, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.33, 0.58, 0.14, 0.37, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.6, 0.81, 0.91, 0.4, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.81, 0.26, 0.76, 0.17, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.9, 0.76, 0.86, 0.27, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.15, 0.19, 0.38, 0.3, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.53, 0.28, 0.5, 0.22, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.21, 0.96, 0.51, 0.83, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.16, 0.51, 0.29, 0.14, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.58, 0.73, 0.48, 0.79, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.18, 0.9, 0.39, 0.46, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.5, 0.17, 0.22, 0.78, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.54, 0.95, 0.94, 0.85, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.46, 0.42, 0.76, 0.85, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.76, 0.17, 0.98, 0.55, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.17, 0.18, 0.73, 0.26, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.48, 0.96, 0.38, 0.25, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.29, 0.46, 0.85, 0.27, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.95, 0.39, 0.54, 0.19, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.52, 0.52, 0.56, 0.31, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.69, 0.92, 0.41, 0.51, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.85, 0.65, 0.44, 0.59, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.51, 0.71, 0.2, 0.14, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.18, 0.93, 0.23, 0.61, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.43, 0.14, 0.51, 0.63, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.13, 0.31, 0.54, 0.83, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.11, 0.55, 0.74, 0.41, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.12, 0.58, 0.61, 0.65, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.25, 0.75, 0.97, 0.95, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.15, 0.91, 0.1, 0.42, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.34, 0.56, 0.3, 0.6, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.4, 0.13, 0.35, 0.89, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.77, 0.28, 0.2, 0.18, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.47, 0.94, 0.28, 0.11, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.89, 0.42, 0.85, 0.59, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.3, 0.87, 0.44, 0.97, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.45, 0.5, 0.91, 0.73, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.93, 0.62, 0.26, 0.61, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.12, 0.9, 0.92, 0.8, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.7, 0.46, 0.84, 0.52, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.44, 0.86, 0.86, 0.25, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.59, 0.77, 0.76, 0.13, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.21, 0.41, 0.28, 0.55, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.64, 0.55, 0.91, 0.22, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.42, 0.33, 0.65, 0.44, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.63, 0.93, 0.35, 0.87, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.79, 0.94, 0.16, 0.24, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.77, 0.62, 0.67, 0.37, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.15, 0.65, 0.46, 0.86, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.89, 0.51, 0.73, 0.93, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.96, 0.1, 0.55, 0.99, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.36, 0.2, 0.17, 0.77, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.54, 0.28, 0.74, 0.63, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.15, 0.35, 0.42, 0.44, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.23, 0.99, 0.58, 0.31, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.45, 0.43, 0.1, 0.88, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.32, 0.84, 0.28, 0.34, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.37, 0.78, 0.87, 0.78, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.4, 0.41, 0.47, 0.22, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.43, 0.54, 0.13, 0.28, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.18, 0.63, 0.39, 0.93, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.23, 0.11, 0.19, 0.14, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.61, 0.67, 0.78, 0.77, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.11, 0.79, 0.96, 0.14, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.69, 0.1, 0.11, 0.85, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.55, 0.91, 0.73, 0.5, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.2, 0.25, 0.81, 0.77, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.61, 0.76, 0.31, 0.21, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.9, 0.39, 0.77, 0.23, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.29, 0.46, 0.38, 0.28, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.28, 0.74, 0.65, 0.11, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.34, 0.75, 0.8, 0.43, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.38, 0.51, 0.52, 0.1, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.73, 0.11, 0.33, 0.3, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.93, 0.52, 0.71, 0.43, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.23, 0.79, 0.64, 0.48, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.51, 0.66, 0.57, 0.95, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.6, 0.11, 0.38, 0.11, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.4, 0.12, 0.95, 0.62, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.23, 0.1, 0.29, 0.49, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.65, 0.32, 0.29, 0.71, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.74, 0.55, 0.66, 0.73, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.83, 0.94, 0.36, 0.23, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.71, 0.82, 0.67, 0.69, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.9, 0.62, 0.74, 0.69, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.48, 0.91, 0.36, 0.74, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.12, 0.99, 0.12, 0.13, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.13, 0.71, 0.13, 0.76, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.4, 0.68, 0.39, 0.64, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.72, 0.73, 0.12, 0.19, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.38, 0.25, 0.4, 0.27, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.62, 0.96, 0.78, 0.82, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.16, 0.35, 0.2, 0.11, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.9, 0.95, 0.78, 0.46, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.11, 0.86, 0.86, 0.51, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.27, 0.42, 0.42, 0.71, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.63, 0.34, 0.27, 0.51, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.22, 0.61, 0.12, 0.94, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.63, 0.38, 0.23, 0.13, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.16, 0.24, 0.61, 0.45, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.5, 0.28, 0.66, 0.42, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.54, 0.77, 0.61, 0.63, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.34, 0.86, 0.43, 0.62, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.86, 0.49, 0.73, 0.95, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.1, 0.44, 0.91, 0.36, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.15, 0.65, 0.61, 0.21, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.19, 0.76, 0.87, 0.18, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.56, 0.96, 0.69, 0.71, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.6, 0.67, 0.52, 0.83, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.12, 0.78, 0.7, 0.89, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.8, 0.23, 0.55, 0.96, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.32, 0.99, 0.89, 0.42, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.72, 0.74, 0.24, 0.62, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.3, 0.75, 0.29, 0.23, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.32, 0.29, 0.59, 0.21, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.51, 0.59, 0.9, 0.39, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.53, 0.6, 0.62, 0.8, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.61, 0.31, 0.72, 0.24, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.25, 0.43, 0.37, 0.49, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.37, 0.8, 0.64, 0.25, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.29, 0.7, 0.84, 0.73, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.35, 0.95, 0.47, 0.84, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.83, 0.69, 0.53, 0.73, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.67, 0.75, 0.33, 0.94, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.98, 0.93, 0.78, 0.58, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.64, 0.76, 0.72, 0.21, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.29, 0.24, 0.31, 0.31, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.24, 0.13, 0.28, 0.28, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.17, 0.23, 0.51, 0.2, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.48, 0.51, 0.7, 0.31, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.59, 0.7, 0.11, 0.79, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.99, 0.3, 0.81, 0.19, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.25, 0.58, 0.47, 0.73, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.43, 0.92, 0.72, 0.58, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.93, 0.59, 0.2, 0.91, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.47, 0.37, 0.37, 0.97, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.92, 0.25, 0.45, 0.85, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.94, 0.67, 0.14, 0.82, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.77, 0.76, 0.83, 0.23, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.79, 0.72, 0.35, 0.34, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.91, 0.72, 0.18, 0.68, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.52, 0.31, 0.22, 0.41, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.42, 0.6, 0.28, 0.33, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.82, 0.66, 0.99, 0.17, 1.0, 0.0, 1.0, 0.0),\n",
       " (0.6, 0.34, 0.23, 0.78, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.78, 0.41, 0.19, 0.59, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.66, 0.84, 0.56, 0.54, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.78, 0.59, 0.25, 0.69, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.49, 0.73, 0.25, 0.79, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.95, 0.98, 0.81, 0.96, 1.0, 1.0, 1.0, 1.0),\n",
       " (0.11, 0.85, 0.28, 0.41, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.52, 0.21, 0.14, 0.37, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.41, 0.79, 0.88, 0.11, 0.0, 1.0, 1.0, 0.0),\n",
       " (0.65, 0.34, 0.52, 0.67, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.52, 0.36, 0.97, 0.17, 0.0, 0.0, 1.0, 0.0),\n",
       " (0.61, 0.76, 0.75, 0.93, 0.0, 1.0, 1.0, 1.0),\n",
       " (0.28, 0.21, 0.31, 0.39, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.64, 0.36, 0.11, 0.27, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.37, 0.59, 0.5, 0.98, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.74, 0.44, 0.52, 0.93, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.15, 0.35, 0.84, 0.99, 0.0, 0.0, 1.0, 1.0),\n",
       " (0.79, 0.4, 0.58, 0.81, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.96, 0.78, 0.73, 0.18, 1.0, 1.0, 1.0, 0.0),\n",
       " (0.68, 0.73, 0.53, 0.81, 0.0, 1.0, 0.0, 1.0),\n",
       " (0.58, 0.9, 0.52, 0.34, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.86, 0.17, 0.91, 0.84, 1.0, 0.0, 1.0, 1.0),\n",
       " (0.22, 0.54, 0.42, 0.66, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.81, 0.59, 0.65, 0.66, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.35, 0.27, 0.63, 0.58, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.27, 0.43, 0.32, 0.51, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.19, 0.82, 0.39, 0.32, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.1, 0.18, 0.12, 0.88, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.47, 0.79, 0.55, 0.58, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.52, 0.62, 0.23, 0.24, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.85, 0.86, 0.33, 0.59, 1.0, 1.0, 0.0, 0.0),\n",
       " (0.36, 0.16, 0.4, 0.89, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.56, 0.63, 0.29, 0.77, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.74, 0.56, 0.36, 0.18, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.62, 0.52, 0.21, 0.87, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.47, 0.61, 0.51, 0.25, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.4, 0.86, 0.35, 0.68, 0.0, 1.0, 0.0, 0.0),\n",
       " (0.37, 0.44, 0.23, 0.69, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.34, 0.4, 0.55, 0.58, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.49, 0.55, 0.63, 0.83, 0.0, 0.0, 0.0, 1.0),\n",
       " (0.93, 0.1, 0.17, 0.8, 1.0, 0.0, 0.0, 1.0),\n",
       " (0.97, 0.44, 0.52, 0.11, 1.0, 0.0, 0.0, 0.0),\n",
       " (0.62, 0.35, 0.54, 0.6, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.45, 0.25, 0.28, 0.28, 0.0, 0.0, 0.0, 0.0),\n",
       " (0.69, 0.56, 0.19, 0.18, 0.0, 0.0, 0.0, 0.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_add = \"INSERT INTO hw_data (CPU_Speed,Ram_Activity,Diks,Network_Activity,cpu_status,ram_status,diks_status,network_status) VALUES (%s,%s,%s,%s,%s,%s,%s,%s)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.executemany(query_add,data_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conenct.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conenct.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPU Speed</th>\n",
       "      <th>Ram Activation</th>\n",
       "      <th>Diks</th>\n",
       "      <th>Network Activity</th>\n",
       "      <th>CPU Status</th>\n",
       "      <th>Ram Status</th>\n",
       "      <th>Diks Status</th>\n",
       "      <th>Network Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CPU Speed  Ram Activation  Diks  Network Activity  CPU Status  \\\n",
       "0         0.63            0.53  0.62              0.23           0   \n",
       "1         0.71            0.65  0.75              0.27           1   \n",
       "2         0.26            0.49  0.81              0.21           0   \n",
       "3         0.59            0.32  0.95              0.56           0   \n",
       "4         0.98            0.10  0.97              0.40           1   \n",
       "..         ...             ...   ...               ...         ...   \n",
       "995       0.77            0.82  0.16              0.85           1   \n",
       "996       0.54            0.26  0.98              0.19           0   \n",
       "997       0.59            0.44  0.12              0.89           0   \n",
       "998       0.45            0.91  0.49              0.26           0   \n",
       "999       0.54            0.48  0.74              0.85           0   \n",
       "\n",
       "     Ram Status  Diks Status  Network Status  \n",
       "0             0            0               0  \n",
       "1             0            1               0  \n",
       "2             0            1               0  \n",
       "3             0            1               0  \n",
       "4             0            1               0  \n",
       "..          ...          ...             ...  \n",
       "995           1            0               1  \n",
       "996           0            1               0  \n",
       "997           0            0               1  \n",
       "998           1            0               0  \n",
       "999           0            1               1  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array(([[data_set['CPU Status']],[data_set['Diks Status']],[data_set['Ram Status']],[data_set['Network Status']]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = data_set['Ram Status'] + data_set['CPU Status'] + data_set['Diks Status'] + data_set['Network Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter\n",
    "y = []\n",
    "for i in range(len(counter)) :\n",
    "    if counter[i] > 2 :\n",
    "        y.append(1)\n",
    "    else :\n",
    "        y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_status_Machines = RandomForestClassifier(n_estimators=500,criterion='entropy',max_leaf_nodes=16,verbose=1,min_samples_split=20,min_samples_leaf=10,max_depth=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data_set,y,test_size=0.3,random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=32, max_leaf_nodes=16,\n",
       "                       min_samples_leaf=10, min_samples_split=20,\n",
       "                       n_estimators=500, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=32, max_leaf_nodes=16,\n",
       "                       min_samples_leaf=10, min_samples_split=20,\n",
       "                       n_estimators=500, verbose=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=32, max_leaf_nodes=16,\n",
       "                       min_samples_leaf=10, min_samples_split=20,\n",
       "                       n_estimators=500, verbose=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checking_status_Machines.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       269\n",
      "           1       1.00      0.61      0.76        31\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.98      0.81      0.87       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "y_pred = checking_status_Machines.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checking_status_Machines.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "joblib.dump(checking_status_Machines,'checking_status_Machines.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPU Speed</th>\n",
       "      <th>Ram Activation</th>\n",
       "      <th>Diks</th>\n",
       "      <th>Network Activity</th>\n",
       "      <th>CPU Status</th>\n",
       "      <th>Ram Status</th>\n",
       "      <th>Diks Status</th>\n",
       "      <th>Network Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CPU Speed  Ram Activation  Diks  Network Activity  CPU Status  \\\n",
       "0         0.79            0.46  0.29              0.84           1   \n",
       "1         0.36            0.30  0.73              0.36           0   \n",
       "2         0.10            0.72  0.63              0.52           0   \n",
       "3         0.74            0.16  0.92              0.12           1   \n",
       "4         0.92            0.21  0.53              0.45           1   \n",
       "..         ...             ...   ...               ...         ...   \n",
       "995       0.55            0.38  0.69              0.44           0   \n",
       "996       0.85            0.40  0.29              0.75           1   \n",
       "997       0.52            0.50  0.91              0.59           0   \n",
       "998       0.13            0.94  0.99              0.38           0   \n",
       "999       0.35            0.93  0.90              0.41           0   \n",
       "\n",
       "     Ram Status  Diks Status  Network Status  \n",
       "0             0            0               1  \n",
       "1             0            1               0  \n",
       "2             1            0               0  \n",
       "3             0            1               0  \n",
       "4             0            0               0  \n",
       "..          ...          ...             ...  \n",
       "995           0            0               0  \n",
       "996           0            0               1  \n",
       "997           0            1               0  \n",
       "998           1            1               0  \n",
       "999           1            1               0  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_checker = LogisticRegression(penalty='l1',verbose=1,solver='liblinear')\n",
    "ram_checker = LogisticRegression(penalty='l2',verbose=2,warm_start=True)\n",
    "Disk_checker = LogisticRegression(penalty='l2',verbose=2,warm_start=True)\n",
    "Network_Checker = LogisticRegression(penalty='l2',warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data_set['CPU Speed'].values.reshape(-1,1),data_set['CPU Status'].values.reshape(-1,1),random_state=12,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;, verbose=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='liblinear', verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_checker.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cpu_checker.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       168\n",
      "           1       1.00      1.00      1.00        82\n",
      "\n",
      "    accuracy                           1.00       250\n",
      "   macro avg       1.00      1.00      1.00       250\n",
      "weighted avg       1.00      1.00      1.00       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cpu_checker.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cpu_checker,'cpu_checker.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data_set['Diks'].values.reshape(-1,1),data_set['Diks Status'].values.reshape(-1,1),random_state=12,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(verbose=2, warm_start=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(verbose=2, warm_start=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(verbose=2, warm_start=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Disk_checker.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Disk_checker.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Disk_checker.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(Disk_checker,'Disk_checker.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data_set['Ram Activation'].values.reshape(-1,1),data_set['Ram Status'],test_size=0.25,random_state=134)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(verbose=2, warm_start=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(verbose=2, warm_start=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(verbose=2, warm_start=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ram_checker.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ram_checker.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ram_checker.pkl']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ram_checker,'ram_checker.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data_set['Network Activity'].values.reshape(-1,1),data_set['Network Status'].values.reshape(-1,1),test_size=0.25,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(warm_start=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(warm_start=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(warm_start=True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Network_Checker.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Network_Checker.pkl']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(Network_Checker,'Network_Checker.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ram_info = np.array([np.random.randint(0,2) for i in range(500)])\n",
    "diks_info = np.array([np.random.randint(0,2) for i in range(500)])\n",
    "cpu_info = np.array([np.random.randint(0,2) for i in range(500)])\n",
    "network_info = np.array([np.random.randint(0,2) for i in range(500)])\n",
    "level_abnormal = np.array([(ram_info + diks_info + cpu_info + network_info)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [4],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_abnormal.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = level_abnormal.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [4],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.DataFrame(data={'ram' : ram_info,'diks' : diks_info,'cpu' : cpu_info,'network' : network_info})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_set.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 0, 1],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 1, 1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_level = keras.Sequential(\n",
    "    [keras.Input(shape=(4,)),\n",
    "     layers.Dense(256,activation='relu',kernel_regularizer=keras.regularizers.l1()),\n",
    "     layers.Dense(128,activation='relu',kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "     layers.Dense(64,activation='relu'),\n",
    "     layers.Dense(5,activation='softmax')\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_level.compile(loss='sparse_categorical_crossentropy',optimizer=keras.optimizers.Adam(learning_rate=0.0001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3706 - loss: 1.5835\n",
      "Epoch 2/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3549 - loss: 1.5547 \n",
      "Epoch 3/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3567 - loss: 1.5243 \n",
      "Epoch 4/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3517 - loss: 1.4991 \n",
      "Epoch 5/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3838 - loss: 1.4642\n",
      "Epoch 6/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3412 - loss: 1.4978 \n",
      "Epoch 7/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3689 - loss: 1.4386 \n",
      "Epoch 8/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3697 - loss: 1.4706 \n",
      "Epoch 9/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3758 - loss: 1.4489 \n",
      "Epoch 10/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3597 - loss: 1.4364 \n",
      "Epoch 11/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3601 - loss: 1.4461 \n",
      "Epoch 12/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3811 - loss: 1.4149\n",
      "Epoch 13/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3819 - loss: 1.4241\n",
      "Epoch 14/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3438 - loss: 1.4219 \n",
      "Epoch 15/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3996 - loss: 1.4289 \n",
      "Epoch 16/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3737 - loss: 1.4238 \n",
      "Epoch 17/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3751 - loss: 1.4197 \n",
      "Epoch 18/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3572 - loss: 1.4368\n",
      "Epoch 19/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3512 - loss: 1.4434 \n",
      "Epoch 20/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3948 - loss: 1.4128 \n",
      "Epoch 21/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3715 - loss: 1.4369 \n",
      "Epoch 22/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3681 - loss: 1.4431 \n",
      "Epoch 23/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3589 - loss: 1.4075 \n",
      "Epoch 24/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3695 - loss: 1.4120 \n",
      "Epoch 25/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3377 - loss: 1.4354 \n",
      "Epoch 26/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3363 - loss: 1.4318  \n",
      "Epoch 27/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3360 - loss: 1.4041 \n",
      "Epoch 28/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3298 - loss: 1.4338 \n",
      "Epoch 29/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3402 - loss: 1.4653 \n",
      "Epoch 30/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3561 - loss: 1.4288 \n",
      "Epoch 31/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3939 - loss: 1.3955 \n",
      "Epoch 32/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3585 - loss: 1.4345 \n",
      "Epoch 33/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3618 - loss: 1.4365 \n",
      "Epoch 34/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3362 - loss: 1.4150 \n",
      "Epoch 35/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3706 - loss: 1.3894 \n",
      "Epoch 36/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3265 - loss: 1.4365 \n",
      "Epoch 37/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3866 - loss: 1.4063 \n",
      "Epoch 38/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3481 - loss: 1.4487 \n",
      "Epoch 39/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3695 - loss: 1.3964 \n",
      "Epoch 40/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3303 - loss: 1.4075 \n",
      "Epoch 41/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3624 - loss: 1.4245\n",
      "Epoch 42/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3482 - loss: 1.4015 \n",
      "Epoch 43/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3776 - loss: 1.4170 \n",
      "Epoch 44/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3445 - loss: 1.4042 \n",
      "Epoch 45/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3409 - loss: 1.4226 \n",
      "Epoch 46/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3522 - loss: 1.3947 \n",
      "Epoch 47/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3574 - loss: 1.4150  \n",
      "Epoch 48/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3653 - loss: 1.3897 \n",
      "Epoch 49/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3967 - loss: 1.3687 \n",
      "Epoch 50/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3751 - loss: 1.3927 \n",
      "Epoch 51/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3712 - loss: 1.3964 \n",
      "Epoch 52/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3727 - loss: 1.4157\n",
      "Epoch 53/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 1.3842\n",
      "Epoch 54/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3599 - loss: 1.4084 \n",
      "Epoch 55/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4041 - loss: 1.3751 \n",
      "Epoch 56/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4064 - loss: 1.3713 \n",
      "Epoch 57/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3760 - loss: 1.4476 \n",
      "Epoch 58/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3962 - loss: 1.3856\n",
      "Epoch 59/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4103 - loss: 1.3584 \n",
      "Epoch 60/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3817 - loss: 1.3780 \n",
      "Epoch 61/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3860 - loss: 1.4025 \n",
      "Epoch 62/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3721 - loss: 1.3874 \n",
      "Epoch 63/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3827 - loss: 1.4042 \n",
      "Epoch 64/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3513 - loss: 1.4200\n",
      "Epoch 65/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3528 - loss: 1.4199\n",
      "Epoch 66/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4051 - loss: 1.3875 \n",
      "Epoch 67/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3916 - loss: 1.3720\n",
      "Epoch 68/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3940 - loss: 1.4267 \n",
      "Epoch 69/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3672 - loss: 1.4309 \n",
      "Epoch 70/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3529 - loss: 1.4134 \n",
      "Epoch 71/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3779 - loss: 1.3725 \n",
      "Epoch 72/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3964 - loss: 1.3838 \n",
      "Epoch 73/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3771 - loss: 1.4218 \n",
      "Epoch 74/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3591 - loss: 1.3740\n",
      "Epoch 75/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4096 - loss: 1.3695\n",
      "Epoch 76/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3997 - loss: 1.4009 \n",
      "Epoch 77/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3979 - loss: 1.3651 \n",
      "Epoch 78/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3803 - loss: 1.3651 \n",
      "Epoch 79/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3727 - loss: 1.3818 \n",
      "Epoch 80/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3708 - loss: 1.3704 \n",
      "Epoch 81/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4019 - loss: 1.3732 \n",
      "Epoch 82/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4079 - loss: 1.3684 \n",
      "Epoch 83/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3990 - loss: 1.3736\n",
      "Epoch 84/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3573 - loss: 1.4105 \n",
      "Epoch 85/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3929 - loss: 1.3966 \n",
      "Epoch 86/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3933 - loss: 1.3669 \n",
      "Epoch 87/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3839 - loss: 1.3848\n",
      "Epoch 88/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4128 - loss: 1.3731 \n",
      "Epoch 89/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3863 - loss: 1.3783 \n",
      "Epoch 90/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4177 - loss: 1.3614 \n",
      "Epoch 91/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3954 - loss: 1.3608 \n",
      "Epoch 92/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3994 - loss: 1.3790 \n",
      "Epoch 93/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3645 - loss: 1.3995 \n",
      "Epoch 94/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3819 - loss: 1.3733 \n",
      "Epoch 95/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3763 - loss: 1.3942 \n",
      "Epoch 96/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3975 - loss: 1.3740 \n",
      "Epoch 97/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3760 - loss: 1.3862 \n",
      "Epoch 98/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4263 - loss: 1.3636  \n",
      "Epoch 99/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4030 - loss: 1.3408 \n",
      "Epoch 100/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3943 - loss: 1.3880 \n",
      "Epoch 101/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3998 - loss: 1.3751 \n",
      "Epoch 102/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4060 - loss: 1.3887 \n",
      "Epoch 103/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4059 - loss: 1.3539 \n",
      "Epoch 104/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3636 - loss: 1.3894\n",
      "Epoch 105/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3826 - loss: 1.3679 \n",
      "Epoch 106/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3805 - loss: 1.3827 \n",
      "Epoch 107/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3705 - loss: 1.3962\n",
      "Epoch 108/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3825 - loss: 1.4033 \n",
      "Epoch 109/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3923 - loss: 1.3772 \n",
      "Epoch 110/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3959 - loss: 1.3754\n",
      "Epoch 111/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3794 - loss: 1.3867\n",
      "Epoch 112/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4020 - loss: 1.3903 \n",
      "Epoch 113/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3900 - loss: 1.3890 \n",
      "Epoch 114/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3980 - loss: 1.3690 \n",
      "Epoch 115/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3747 - loss: 1.3700 \n",
      "Epoch 116/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3951 - loss: 1.3665 \n",
      "Epoch 117/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3715 - loss: 1.3974 \n",
      "Epoch 118/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3888 - loss: 1.3954 \n",
      "Epoch 119/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3528 - loss: 1.4142\n",
      "Epoch 120/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4029 - loss: 1.3812\n",
      "Epoch 121/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3734 - loss: 1.3793\n",
      "Epoch 122/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3794 - loss: 1.4011\n",
      "Epoch 123/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3677 - loss: 1.4143\n",
      "Epoch 124/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3895 - loss: 1.3873 \n",
      "Epoch 125/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3645 - loss: 1.3752 \n",
      "Epoch 126/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3659 - loss: 1.3866 \n",
      "Epoch 127/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3717 - loss: 1.3951 \n",
      "Epoch 128/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3925 - loss: 1.3684 \n",
      "Epoch 129/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3936 - loss: 1.3445\n",
      "Epoch 130/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4060 - loss: 1.3354\n",
      "Epoch 131/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3921 - loss: 1.3632\n",
      "Epoch 132/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3728 - loss: 1.4025 \n",
      "Epoch 133/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4079 - loss: 1.3684 \n",
      "Epoch 134/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3829 - loss: 1.3586 \n",
      "Epoch 135/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3999 - loss: 1.3736 \n",
      "Epoch 136/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3960 - loss: 1.3932 \n",
      "Epoch 137/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3971 - loss: 1.4294 \n",
      "Epoch 138/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4076 - loss: 1.3675 \n",
      "Epoch 139/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4271 - loss: 1.3480  \n",
      "Epoch 140/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3995 - loss: 1.3809 \n",
      "Epoch 141/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4117 - loss: 1.3981\n",
      "Epoch 142/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4216 - loss: 1.3527 \n",
      "Epoch 143/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4019 - loss: 1.3421\n",
      "Epoch 144/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3717 - loss: 1.3693 \n",
      "Epoch 145/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3648 - loss: 1.3764 \n",
      "Epoch 146/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3765 - loss: 1.3747 \n",
      "Epoch 147/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3650 - loss: 1.4010\n",
      "Epoch 148/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4071 - loss: 1.3835 \n",
      "Epoch 149/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4119 - loss: 1.3315\n",
      "Epoch 150/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3972 - loss: 1.3831 \n",
      "Epoch 151/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3876 - loss: 1.3601 \n",
      "Epoch 152/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3790 - loss: 1.4102 \n",
      "Epoch 153/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4195 - loss: 1.3852 \n",
      "Epoch 154/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3897 - loss: 1.3870 \n",
      "Epoch 155/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3939 - loss: 1.3931 \n",
      "Epoch 156/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4064 - loss: 1.3680  \n",
      "Epoch 157/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3753 - loss: 1.3917 \n",
      "Epoch 158/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4164 - loss: 1.3453 \n",
      "Epoch 159/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4063 - loss: 1.3596 \n",
      "Epoch 160/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3723 - loss: 1.3635\n",
      "Epoch 161/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3632 - loss: 1.3886\n",
      "Epoch 162/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3625 - loss: 1.3690 \n",
      "Epoch 163/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4026 - loss: 1.3544 \n",
      "Epoch 164/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3917 - loss: 1.3819 \n",
      "Epoch 165/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3714 - loss: 1.3776 \n",
      "Epoch 166/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4071 - loss: 1.3595 \n",
      "Epoch 167/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3623 - loss: 1.4239 \n",
      "Epoch 168/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3981 - loss: 1.3752 \n",
      "Epoch 169/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4180 - loss: 1.3558 \n",
      "Epoch 170/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3843 - loss: 1.3911\n",
      "Epoch 171/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4163 - loss: 1.3585 \n",
      "Epoch 172/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4220 - loss: 1.3450\n",
      "Epoch 173/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3979 - loss: 1.3702\n",
      "Epoch 174/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3711 - loss: 1.3566 \n",
      "Epoch 175/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3854 - loss: 1.3625 \n",
      "Epoch 176/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3606 - loss: 1.3997 \n",
      "Epoch 177/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3801 - loss: 1.3798 \n",
      "Epoch 178/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4029 - loss: 1.3622  \n",
      "Epoch 179/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4182 - loss: 1.3754\n",
      "Epoch 180/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3835 - loss: 1.3741 \n",
      "Epoch 181/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4056 - loss: 1.3643\n",
      "Epoch 182/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3833 - loss: 1.3746 \n",
      "Epoch 183/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3843 - loss: 1.3960 \n",
      "Epoch 184/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3964 - loss: 1.3484\n",
      "Epoch 185/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3801 - loss: 1.4059 \n",
      "Epoch 186/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3797 - loss: 1.3853 \n",
      "Epoch 187/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3942 - loss: 1.3752 \n",
      "Epoch 188/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3793 - loss: 1.3814 \n",
      "Epoch 189/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3779 - loss: 1.3960 \n",
      "Epoch 190/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4071 - loss: 1.3701 \n",
      "Epoch 191/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3739 - loss: 1.3860\n",
      "Epoch 192/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4114 - loss: 1.3531 \n",
      "Epoch 193/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4011 - loss: 1.3763 \n",
      "Epoch 194/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4295 - loss: 1.3356 \n",
      "Epoch 195/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3952 - loss: 1.3473 \n",
      "Epoch 196/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4051 - loss: 1.3548\n",
      "Epoch 197/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3678 - loss: 1.3883 \n",
      "Epoch 198/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3911 - loss: 1.3577 \n",
      "Epoch 199/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3670 - loss: 1.3709 \n",
      "Epoch 200/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4143 - loss: 1.3362\n",
      "Epoch 201/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4093 - loss: 1.3454 \n",
      "Epoch 202/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3957 - loss: 1.3943 \n",
      "Epoch 203/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3885 - loss: 1.3884 \n",
      "Epoch 204/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3976 - loss: 1.3740 \n",
      "Epoch 205/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4099 - loss: 1.3681\n",
      "Epoch 206/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4030 - loss: 1.3576 \n",
      "Epoch 207/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3923 - loss: 1.3860 \n",
      "Epoch 208/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3855 - loss: 1.4198 \n",
      "Epoch 209/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4288 - loss: 1.3176 \n",
      "Epoch 210/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4034 - loss: 1.3750\n",
      "Epoch 211/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3613 - loss: 1.3784 \n",
      "Epoch 212/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3755 - loss: 1.3754 \n",
      "Epoch 213/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3682 - loss: 1.4006 \n",
      "Epoch 214/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3801 - loss: 1.3979 \n",
      "Epoch 215/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3671 - loss: 1.3745 \n",
      "Epoch 216/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4167 - loss: 1.3878 \n",
      "Epoch 217/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3847 - loss: 1.3860 \n",
      "Epoch 218/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3805 - loss: 1.3872 \n",
      "Epoch 219/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4200 - loss: 1.3598 \n",
      "Epoch 220/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3647 - loss: 1.3832 \n",
      "Epoch 221/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3874 - loss: 1.3793\n",
      "Epoch 222/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4213 - loss: 1.3405\n",
      "Epoch 223/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3942 - loss: 1.3747\n",
      "Epoch 224/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3870 - loss: 1.3633 \n",
      "Epoch 225/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3858 - loss: 1.3602\n",
      "Epoch 226/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3678 - loss: 1.3800 \n",
      "Epoch 227/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3919 - loss: 1.3857 \n",
      "Epoch 228/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4016 - loss: 1.3853 \n",
      "Epoch 229/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3901 - loss: 1.3563 \n",
      "Epoch 230/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3837 - loss: 1.3682 \n",
      "Epoch 231/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4022 - loss: 1.3937 \n",
      "Epoch 232/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3953 - loss: 1.3714 \n",
      "Epoch 233/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3848 - loss: 1.3746 \n",
      "Epoch 234/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3837 - loss: 1.3869 \n",
      "Epoch 235/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4073 - loss: 1.3544 \n",
      "Epoch 236/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3921 - loss: 1.3585\n",
      "Epoch 237/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4007 - loss: 1.4093 \n",
      "Epoch 238/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3693 - loss: 1.3743 \n",
      "Epoch 239/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3885 - loss: 1.3728\n",
      "Epoch 240/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3848 - loss: 1.3814 \n",
      "Epoch 241/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3821 - loss: 1.3867 \n",
      "Epoch 242/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4245 - loss: 1.3518 \n",
      "Epoch 243/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3471 - loss: 1.3961  \n",
      "Epoch 244/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3871 - loss: 1.3561 \n",
      "Epoch 245/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3975 - loss: 1.3624 \n",
      "Epoch 246/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3919 - loss: 1.3737\n",
      "Epoch 247/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3846 - loss: 1.3918 \n",
      "Epoch 248/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3938 - loss: 1.3909\n",
      "Epoch 249/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4138 - loss: 1.3517 \n",
      "Epoch 250/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3950 - loss: 1.3378 \n",
      "Epoch 251/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3896 - loss: 1.3603 \n",
      "Epoch 252/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3903 - loss: 1.3708 \n",
      "Epoch 253/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3975 - loss: 1.3743 \n",
      "Epoch 254/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3846 - loss: 1.3893\n",
      "Epoch 255/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3779 - loss: 1.3942 \n",
      "Epoch 256/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3802 - loss: 1.3764 \n",
      "Epoch 257/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3932 - loss: 1.3948 \n",
      "Epoch 258/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3851 - loss: 1.3709 \n",
      "Epoch 259/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4241 - loss: 1.3696 \n",
      "Epoch 260/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3948 - loss: 1.3600 \n",
      "Epoch 261/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3802 - loss: 1.3516 \n",
      "Epoch 262/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3753 - loss: 1.3751 \n",
      "Epoch 263/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4073 - loss: 1.3656 \n",
      "Epoch 264/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3967 - loss: 1.3746\n",
      "Epoch 265/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4115 - loss: 1.3550\n",
      "Epoch 266/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3822 - loss: 1.3508 \n",
      "Epoch 267/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3965 - loss: 1.3718 \n",
      "Epoch 268/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3925 - loss: 1.3989 \n",
      "Epoch 269/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4109 - loss: 1.3467 \n",
      "Epoch 270/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3857 - loss: 1.3968 \n",
      "Epoch 271/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3853 - loss: 1.3991\n",
      "Epoch 272/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4245 - loss: 1.3573 \n",
      "Epoch 273/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3878 - loss: 1.4110 \n",
      "Epoch 274/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3584 - loss: 1.3599 \n",
      "Epoch 275/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3812 - loss: 1.3760 \n",
      "Epoch 276/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3583 - loss: 1.3851 \n",
      "Epoch 277/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3868 - loss: 1.3921\n",
      "Epoch 278/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3568 - loss: 1.4049 \n",
      "Epoch 279/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3882 - loss: 1.3680 \n",
      "Epoch 280/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3616 - loss: 1.3816 \n",
      "Epoch 281/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4167 - loss: 1.3429 \n",
      "Epoch 282/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3815 - loss: 1.3639 \n",
      "Epoch 283/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3945 - loss: 1.3828 \n",
      "Epoch 284/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3945 - loss: 1.3550 \n",
      "Epoch 285/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3980 - loss: 1.3681 \n",
      "Epoch 286/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3790 - loss: 1.3957\n",
      "Epoch 287/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3764 - loss: 1.3722 \n",
      "Epoch 288/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4075 - loss: 1.3880 \n",
      "Epoch 289/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3936 - loss: 1.3710 \n",
      "Epoch 290/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4011 - loss: 1.3751 \n",
      "Epoch 291/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3793 - loss: 1.3673 \n",
      "Epoch 292/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3841 - loss: 1.3622 \n",
      "Epoch 293/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3877 - loss: 1.3722\n",
      "Epoch 294/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3895 - loss: 1.3559 \n",
      "Epoch 295/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3804 - loss: 1.3643\n",
      "Epoch 296/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3553 - loss: 1.4044\n",
      "Epoch 297/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3615 - loss: 1.4017 \n",
      "Epoch 298/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3543 - loss: 1.3955 \n",
      "Epoch 299/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4000 - loss: 1.3606 \n",
      "Epoch 300/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3837 - loss: 1.3891\n",
      "Epoch 301/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3878 - loss: 1.3527 \n",
      "Epoch 302/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3970 - loss: 1.3922 \n",
      "Epoch 303/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4014 - loss: 1.3725 \n",
      "Epoch 304/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4171 - loss: 1.3347 \n",
      "Epoch 305/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3864 - loss: 1.3814\n",
      "Epoch 306/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3745 - loss: 1.3643 \n",
      "Epoch 307/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3826 - loss: 1.3875 \n",
      "Epoch 308/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3984 - loss: 1.3800 \n",
      "Epoch 309/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3679 - loss: 1.4022 \n",
      "Epoch 310/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4451 - loss: 1.3357 \n",
      "Epoch 311/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3880 - loss: 1.3863 \n",
      "Epoch 312/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4128 - loss: 1.3627 \n",
      "Epoch 313/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3886 - loss: 1.3782\n",
      "Epoch 314/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3787 - loss: 1.3999 \n",
      "Epoch 315/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4209 - loss: 1.3621\n",
      "Epoch 316/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3990 - loss: 1.3486 \n",
      "Epoch 317/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4077 - loss: 1.3569  \n",
      "Epoch 318/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3880 - loss: 1.3748 \n",
      "Epoch 319/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3715 - loss: 1.3828 \n",
      "Epoch 320/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3774 - loss: 1.3774 \n",
      "Epoch 321/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3471 - loss: 1.3685 \n",
      "Epoch 322/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4179 - loss: 1.3209\n",
      "Epoch 323/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3814 - loss: 1.4000\n",
      "Epoch 324/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3888 - loss: 1.3901  \n",
      "Epoch 325/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3897 - loss: 1.3656 \n",
      "Epoch 326/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3577 - loss: 1.4032 \n",
      "Epoch 327/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3666 - loss: 1.4135 \n",
      "Epoch 328/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3840 - loss: 1.3679 \n",
      "Epoch 329/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3753 - loss: 1.3894 \n",
      "Epoch 330/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3787 - loss: 1.3575 \n",
      "Epoch 331/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3992 - loss: 1.3440 \n",
      "Epoch 332/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4138 - loss: 1.3578 \n",
      "Epoch 333/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4167 - loss: 1.3462 \n",
      "Epoch 334/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3841 - loss: 1.3546 \n",
      "Epoch 335/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3726 - loss: 1.3848\n",
      "Epoch 336/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3951 - loss: 1.3756 \n",
      "Epoch 337/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4046 - loss: 1.3786 \n",
      "Epoch 338/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3786 - loss: 1.3972 \n",
      "Epoch 339/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3759 - loss: 1.3759 \n",
      "Epoch 340/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3713 - loss: 1.3968 \n",
      "Epoch 341/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3983 - loss: 1.3676 \n",
      "Epoch 342/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3956 - loss: 1.3536\n",
      "Epoch 343/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4045 - loss: 1.3563  \n",
      "Epoch 344/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4100 - loss: 1.3431 \n",
      "Epoch 345/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3954 - loss: 1.3575 \n",
      "Epoch 346/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3921 - loss: 1.3797 \n",
      "Epoch 347/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4156 - loss: 1.3512\n",
      "Epoch 348/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3764 - loss: 1.3571 \n",
      "Epoch 349/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3911 - loss: 1.3856 \n",
      "Epoch 350/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3786 - loss: 1.3762 \n",
      "Epoch 351/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3968 - loss: 1.3609\n",
      "Epoch 352/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4015 - loss: 1.3450 \n",
      "Epoch 353/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3810 - loss: 1.3657 \n",
      "Epoch 354/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3940 - loss: 1.3438 \n",
      "Epoch 355/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4193 - loss: 1.3476\n",
      "Epoch 356/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3905 - loss: 1.3760\n",
      "Epoch 357/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4097 - loss: 1.3597 \n",
      "Epoch 358/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3780 - loss: 1.4094 \n",
      "Epoch 359/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4037 - loss: 1.3958\n",
      "Epoch 360/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4032 - loss: 1.3576 \n",
      "Epoch 361/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4048 - loss: 1.3625 \n",
      "Epoch 362/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3924 - loss: 1.3623\n",
      "Epoch 363/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3945 - loss: 1.3657 \n",
      "Epoch 364/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4035 - loss: 1.3546 \n",
      "Epoch 365/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3598 - loss: 1.3748 \n",
      "Epoch 366/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3855 - loss: 1.3828 \n",
      "Epoch 367/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3771 - loss: 1.3733 \n",
      "Epoch 368/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4013 - loss: 1.3703 \n",
      "Epoch 369/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3926 - loss: 1.3694 \n",
      "Epoch 370/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3816 - loss: 1.3832 \n",
      "Epoch 371/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4123 - loss: 1.3803\n",
      "Epoch 372/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3702 - loss: 1.3783 \n",
      "Epoch 373/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3726 - loss: 1.3891\n",
      "Epoch 374/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4072 - loss: 1.3621\n",
      "Epoch 375/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3861 - loss: 1.3721\n",
      "Epoch 376/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3614 - loss: 1.4036 \n",
      "Epoch 377/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4022 - loss: 1.3593 \n",
      "Epoch 378/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3811 - loss: 1.3868\n",
      "Epoch 379/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3830 - loss: 1.3762  \n",
      "Epoch 380/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3746 - loss: 1.3519 \n",
      "Epoch 381/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3746 - loss: 1.3880 \n",
      "Epoch 382/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3723 - loss: 1.3894 \n",
      "Epoch 383/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3717 - loss: 1.3990 \n",
      "Epoch 384/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3549 - loss: 1.4217 \n",
      "Epoch 385/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3890 - loss: 1.3749 \n",
      "Epoch 386/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3800 - loss: 1.3584\n",
      "Epoch 387/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3666 - loss: 1.3973 \n",
      "Epoch 388/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3767 - loss: 1.3506 \n",
      "Epoch 389/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3964 - loss: 1.3397 \n",
      "Epoch 390/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4101 - loss: 1.3630 \n",
      "Epoch 391/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3935 - loss: 1.3731 \n",
      "Epoch 392/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3973 - loss: 1.3703 \n",
      "Epoch 393/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3810 - loss: 1.3764 \n",
      "Epoch 394/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3897 - loss: 1.3854 \n",
      "Epoch 395/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3706 - loss: 1.3792 \n",
      "Epoch 396/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4276 - loss: 1.3598\n",
      "Epoch 397/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4056 - loss: 1.3953\n",
      "Epoch 398/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4148 - loss: 1.3284 \n",
      "Epoch 399/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3994 - loss: 1.3678 \n",
      "Epoch 400/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3755 - loss: 1.3903 \n",
      "Epoch 401/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3610 - loss: 1.4259 \n",
      "Epoch 402/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4146 - loss: 1.3527 \n",
      "Epoch 403/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3801 - loss: 1.3701 \n",
      "Epoch 404/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4069 - loss: 1.3607 \n",
      "Epoch 405/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3661 - loss: 1.3853\n",
      "Epoch 406/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3983 - loss: 1.3762 \n",
      "Epoch 407/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3774 - loss: 1.3947 \n",
      "Epoch 408/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3994 - loss: 1.3691\n",
      "Epoch 409/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4139 - loss: 1.3582 \n",
      "Epoch 410/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4016 - loss: 1.3773 \n",
      "Epoch 411/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4073 - loss: 1.3670 \n",
      "Epoch 412/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3843 - loss: 1.3817\n",
      "Epoch 413/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3579 - loss: 1.4184 \n",
      "Epoch 414/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4001 - loss: 1.3803\n",
      "Epoch 415/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4034 - loss: 1.3709 \n",
      "Epoch 416/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3863 - loss: 1.3903 \n",
      "Epoch 417/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3441 - loss: 1.4074\n",
      "Epoch 418/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3995 - loss: 1.3770 \n",
      "Epoch 419/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4272 - loss: 1.3611 \n",
      "Epoch 420/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3725 - loss: 1.3621\n",
      "Epoch 421/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3938 - loss: 1.3381 \n",
      "Epoch 422/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4114 - loss: 1.3585 \n",
      "Epoch 423/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3748 - loss: 1.4057\n",
      "Epoch 424/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3859 - loss: 1.3573 \n",
      "Epoch 425/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3869 - loss: 1.3745 \n",
      "Epoch 426/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4106 - loss: 1.3426\n",
      "Epoch 427/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3911 - loss: 1.3528 \n",
      "Epoch 428/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4041 - loss: 1.3684 \n",
      "Epoch 429/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4101 - loss: 1.3577 \n",
      "Epoch 430/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4022 - loss: 1.3760 \n",
      "Epoch 431/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3515 - loss: 1.3825 \n",
      "Epoch 432/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3906 - loss: 1.3761 \n",
      "Epoch 433/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3762 - loss: 1.3898 \n",
      "Epoch 434/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4361 - loss: 1.3363\n",
      "Epoch 435/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4058 - loss: 1.3663  \n",
      "Epoch 436/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3862 - loss: 1.3626 \n",
      "Epoch 437/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4129 - loss: 1.3227 \n",
      "Epoch 438/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3833 - loss: 1.4001 \n",
      "Epoch 439/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3731 - loss: 1.3931 \n",
      "Epoch 440/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3938 - loss: 1.3842 \n",
      "Epoch 441/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4304 - loss: 1.3436\n",
      "Epoch 442/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3868 - loss: 1.3764 \n",
      "Epoch 443/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3617 - loss: 1.3823 \n",
      "Epoch 444/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4085 - loss: 1.3616\n",
      "Epoch 445/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3893 - loss: 1.3411\n",
      "Epoch 446/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3962 - loss: 1.3841\n",
      "Epoch 447/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3805 - loss: 1.3586 \n",
      "Epoch 448/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3901 - loss: 1.3933 \n",
      "Epoch 449/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3973 - loss: 1.3715 \n",
      "Epoch 450/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3964 - loss: 1.3821\n",
      "Epoch 451/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3770 - loss: 1.3890 \n",
      "Epoch 452/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3822 - loss: 1.3675 \n",
      "Epoch 453/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3996 - loss: 1.3644 \n",
      "Epoch 454/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3909 - loss: 1.3652 \n",
      "Epoch 455/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3857 - loss: 1.3866  \n",
      "Epoch 456/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3885 - loss: 1.3949 \n",
      "Epoch 457/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3876 - loss: 1.3771 \n",
      "Epoch 458/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3765 - loss: 1.3679\n",
      "Epoch 459/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3758 - loss: 1.3748 \n",
      "Epoch 460/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3998 - loss: 1.3722 \n",
      "Epoch 461/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3815 - loss: 1.3883 \n",
      "Epoch 462/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3621 - loss: 1.3803 \n",
      "Epoch 463/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3782 - loss: 1.3996 \n",
      "Epoch 464/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3826 - loss: 1.3624 \n",
      "Epoch 465/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3861 - loss: 1.3884 \n",
      "Epoch 466/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3835 - loss: 1.4014 \n",
      "Epoch 467/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3700 - loss: 1.3968 \n",
      "Epoch 468/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3694 - loss: 1.3865 \n",
      "Epoch 469/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3849 - loss: 1.3820\n",
      "Epoch 470/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4166 - loss: 1.3449  \n",
      "Epoch 471/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3975 - loss: 1.3591 \n",
      "Epoch 472/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4056 - loss: 1.3729 \n",
      "Epoch 473/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3791 - loss: 1.3909 \n",
      "Epoch 474/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4155 - loss: 1.3551 \n",
      "Epoch 475/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4006 - loss: 1.3655\n",
      "Epoch 476/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3898 - loss: 1.3922 \n",
      "Epoch 477/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3945 - loss: 1.3666 \n",
      "Epoch 478/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3868 - loss: 1.3911 \n",
      "Epoch 479/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4084 - loss: 1.3824 \n",
      "Epoch 480/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3982 - loss: 1.3950 \n",
      "Epoch 481/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4026 - loss: 1.3410 \n",
      "Epoch 482/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4075 - loss: 1.3643 \n",
      "Epoch 483/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3751 - loss: 1.3632 \n",
      "Epoch 484/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3802 - loss: 1.3752\n",
      "Epoch 485/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3986 - loss: 1.3736\n",
      "Epoch 486/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3958 - loss: 1.3865 \n",
      "Epoch 487/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3687 - loss: 1.3948 \n",
      "Epoch 488/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4141 - loss: 1.3104 \n",
      "Epoch 489/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4133 - loss: 1.3538 \n",
      "Epoch 490/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3943 - loss: 1.3549\n",
      "Epoch 491/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4113 - loss: 1.3473 \n",
      "Epoch 492/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4093 - loss: 1.3838\n",
      "Epoch 493/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3789 - loss: 1.3540 \n",
      "Epoch 494/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3697 - loss: 1.4067 \n",
      "Epoch 495/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3850 - loss: 1.3817 \n",
      "Epoch 496/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3827 - loss: 1.3865 \n",
      "Epoch 497/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3871 - loss: 1.3810  \n",
      "Epoch 498/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4137 - loss: 1.3368 \n",
      "Epoch 499/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3808 - loss: 1.3835 \n",
      "Epoch 500/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3756 - loss: 1.3728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b913adbda0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal_level.fit(x,y,verbose=1,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Abnormal_clasification = MLPClassifier(hidden_layer_sizes=(256,128,64),activation='relu',solver='adam',learning_rate='invscaling',learning_rate_init=0.0001,verbose=True,max_iter=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1101: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.59539217\n",
      "Iteration 2, loss = 1.58961915\n",
      "Iteration 3, loss = 1.58432741\n",
      "Iteration 4, loss = 1.57927963\n",
      "Iteration 5, loss = 1.57420072\n",
      "Iteration 6, loss = 1.56943250\n",
      "Iteration 7, loss = 1.56484855\n",
      "Iteration 8, loss = 1.56061598\n",
      "Iteration 9, loss = 1.55660722\n",
      "Iteration 10, loss = 1.55288250\n",
      "Iteration 11, loss = 1.54911229\n",
      "Iteration 12, loss = 1.54564746\n",
      "Iteration 13, loss = 1.54209989\n",
      "Iteration 14, loss = 1.53862432\n",
      "Iteration 15, loss = 1.53543380\n",
      "Iteration 16, loss = 1.53222373\n",
      "Iteration 17, loss = 1.52925809\n",
      "Iteration 18, loss = 1.52602498\n",
      "Iteration 19, loss = 1.52298625\n",
      "Iteration 20, loss = 1.52017404\n",
      "Iteration 21, loss = 1.51717760\n",
      "Iteration 22, loss = 1.51464885\n",
      "Iteration 23, loss = 1.51212455\n",
      "Iteration 24, loss = 1.50930902\n",
      "Iteration 25, loss = 1.50680943\n",
      "Iteration 26, loss = 1.50449368\n",
      "Iteration 27, loss = 1.50212911\n",
      "Iteration 28, loss = 1.49979858\n",
      "Iteration 29, loss = 1.49785053\n",
      "Iteration 30, loss = 1.49587504\n",
      "Iteration 31, loss = 1.49399607\n",
      "Iteration 32, loss = 1.49203950\n",
      "Iteration 33, loss = 1.49000481\n",
      "Iteration 34, loss = 1.48839568\n",
      "Iteration 35, loss = 1.48693161\n",
      "Iteration 36, loss = 1.48524225\n",
      "Iteration 37, loss = 1.48384054\n",
      "Iteration 38, loss = 1.48241857\n",
      "Iteration 39, loss = 1.48104361\n",
      "Iteration 40, loss = 1.47981292\n",
      "Iteration 41, loss = 1.47857437\n",
      "Iteration 42, loss = 1.47753302\n",
      "Iteration 43, loss = 1.47648471\n",
      "Iteration 44, loss = 1.47552939\n",
      "Iteration 45, loss = 1.47453269\n",
      "Iteration 46, loss = 1.47352504\n",
      "Iteration 47, loss = 1.47275250\n",
      "Iteration 48, loss = 1.47180569\n",
      "Iteration 49, loss = 1.47110305\n",
      "Iteration 50, loss = 1.47034470\n",
      "Iteration 51, loss = 1.46959046\n",
      "Iteration 52, loss = 1.46891092\n",
      "Iteration 53, loss = 1.46821695\n",
      "Iteration 54, loss = 1.46753840\n",
      "Iteration 55, loss = 1.46698494\n",
      "Iteration 56, loss = 1.46636470\n",
      "Iteration 57, loss = 1.46589307\n",
      "Iteration 58, loss = 1.46523386\n",
      "Iteration 59, loss = 1.46481880\n",
      "Iteration 60, loss = 1.46425202\n",
      "Iteration 61, loss = 1.46383263\n",
      "Iteration 62, loss = 1.46338809\n",
      "Iteration 63, loss = 1.46293116\n",
      "Iteration 64, loss = 1.46252091\n",
      "Iteration 65, loss = 1.46204778\n",
      "Iteration 66, loss = 1.46165001\n",
      "Iteration 67, loss = 1.46129474\n",
      "Iteration 68, loss = 1.46091082\n",
      "Iteration 69, loss = 1.46055161\n",
      "Iteration 70, loss = 1.46022386\n",
      "Iteration 71, loss = 1.45982424\n",
      "Iteration 72, loss = 1.45951173\n",
      "Iteration 73, loss = 1.45919438\n",
      "Iteration 74, loss = 1.45886754\n",
      "Iteration 75, loss = 1.45854174\n",
      "Iteration 76, loss = 1.45822049\n",
      "Iteration 77, loss = 1.45790342\n",
      "Iteration 78, loss = 1.45763750\n",
      "Iteration 79, loss = 1.45727784\n",
      "Iteration 80, loss = 1.45707060\n",
      "Iteration 81, loss = 1.45670765\n",
      "Iteration 82, loss = 1.45643483\n",
      "Iteration 83, loss = 1.45614505\n",
      "Iteration 84, loss = 1.45588814\n",
      "Iteration 85, loss = 1.45559199\n",
      "Iteration 86, loss = 1.45532969\n",
      "Iteration 87, loss = 1.45507550\n",
      "Iteration 88, loss = 1.45481100\n",
      "Iteration 89, loss = 1.45462285\n",
      "Iteration 90, loss = 1.45433584\n",
      "Iteration 91, loss = 1.45410477\n",
      "Iteration 92, loss = 1.45381315\n",
      "Iteration 93, loss = 1.45361189\n",
      "Iteration 94, loss = 1.45333544\n",
      "Iteration 95, loss = 1.45319377\n",
      "Iteration 96, loss = 1.45285470\n",
      "Iteration 97, loss = 1.45259128\n",
      "Iteration 98, loss = 1.45238570\n",
      "Iteration 99, loss = 1.45220768\n",
      "Iteration 100, loss = 1.45189832\n",
      "Iteration 101, loss = 1.45165837\n",
      "Iteration 102, loss = 1.45152002\n",
      "Iteration 103, loss = 1.45120716\n",
      "Iteration 104, loss = 1.45098780\n",
      "Iteration 105, loss = 1.45076471\n",
      "Iteration 106, loss = 1.45054122\n",
      "Iteration 107, loss = 1.45030377\n",
      "Iteration 108, loss = 1.45006898\n",
      "Iteration 109, loss = 1.44985085\n",
      "Iteration 110, loss = 1.44962637\n",
      "Iteration 111, loss = 1.44945398\n",
      "Iteration 112, loss = 1.44926937\n",
      "Iteration 113, loss = 1.44903349\n",
      "Iteration 114, loss = 1.44882047\n",
      "Iteration 115, loss = 1.44859954\n",
      "Iteration 116, loss = 1.44835136\n",
      "Iteration 117, loss = 1.44816324\n",
      "Iteration 118, loss = 1.44796357\n",
      "Iteration 119, loss = 1.44774930\n",
      "Iteration 120, loss = 1.44750339\n",
      "Iteration 121, loss = 1.44733858\n",
      "Iteration 122, loss = 1.44708779\n",
      "Iteration 123, loss = 1.44692353\n",
      "Iteration 124, loss = 1.44668641\n",
      "Iteration 125, loss = 1.44648975\n",
      "Iteration 126, loss = 1.44623315\n",
      "Iteration 127, loss = 1.44603097\n",
      "Iteration 128, loss = 1.44582217\n",
      "Iteration 129, loss = 1.44562463\n",
      "Iteration 130, loss = 1.44540498\n",
      "Iteration 131, loss = 1.44522630\n",
      "Iteration 132, loss = 1.44498221\n",
      "Iteration 133, loss = 1.44478316\n",
      "Iteration 134, loss = 1.44455514\n",
      "Iteration 135, loss = 1.44435889\n",
      "Iteration 136, loss = 1.44415715\n",
      "Iteration 137, loss = 1.44393725\n",
      "Iteration 138, loss = 1.44374298\n",
      "Iteration 139, loss = 1.44351151\n",
      "Iteration 140, loss = 1.44337536\n",
      "Iteration 141, loss = 1.44316757\n",
      "Iteration 142, loss = 1.44294377\n",
      "Iteration 143, loss = 1.44274397\n",
      "Iteration 144, loss = 1.44250394\n",
      "Iteration 145, loss = 1.44231132\n",
      "Iteration 146, loss = 1.44213648\n",
      "Iteration 147, loss = 1.44192069\n",
      "Iteration 148, loss = 1.44172786\n",
      "Iteration 149, loss = 1.44150232\n",
      "Iteration 150, loss = 1.44128190\n",
      "Iteration 151, loss = 1.44109875\n",
      "Iteration 152, loss = 1.44089508\n",
      "Iteration 153, loss = 1.44075078\n",
      "Iteration 154, loss = 1.44049404\n",
      "Iteration 155, loss = 1.44027700\n",
      "Iteration 156, loss = 1.44010671\n",
      "Iteration 157, loss = 1.43988864\n",
      "Iteration 158, loss = 1.43965823\n",
      "Iteration 159, loss = 1.43947934\n",
      "Iteration 160, loss = 1.43934454\n",
      "Iteration 161, loss = 1.43908190\n",
      "Iteration 162, loss = 1.43890192\n",
      "Iteration 163, loss = 1.43871744\n",
      "Iteration 164, loss = 1.43850394\n",
      "Iteration 165, loss = 1.43827962\n",
      "Iteration 166, loss = 1.43816362\n",
      "Iteration 167, loss = 1.43789385\n",
      "Iteration 168, loss = 1.43776572\n",
      "Iteration 169, loss = 1.43751818\n",
      "Iteration 170, loss = 1.43734150\n",
      "Iteration 171, loss = 1.43714477\n",
      "Iteration 172, loss = 1.43700489\n",
      "Iteration 173, loss = 1.43673670\n",
      "Iteration 174, loss = 1.43653836\n",
      "Iteration 175, loss = 1.43640094\n",
      "Iteration 176, loss = 1.43624288\n",
      "Iteration 177, loss = 1.43593692\n",
      "Iteration 178, loss = 1.43579153\n",
      "Iteration 179, loss = 1.43561281\n",
      "Iteration 180, loss = 1.43544101\n",
      "Iteration 181, loss = 1.43517213\n",
      "Iteration 182, loss = 1.43494081\n",
      "Iteration 183, loss = 1.43480835\n",
      "Iteration 184, loss = 1.43456201\n",
      "Iteration 185, loss = 1.43437421\n",
      "Iteration 186, loss = 1.43416829\n",
      "Iteration 187, loss = 1.43395951\n",
      "Iteration 188, loss = 1.43381089\n",
      "Iteration 189, loss = 1.43357705\n",
      "Iteration 190, loss = 1.43345077\n",
      "Iteration 191, loss = 1.43320874\n",
      "Iteration 192, loss = 1.43299579\n",
      "Iteration 193, loss = 1.43281212\n",
      "Iteration 194, loss = 1.43264537\n",
      "Iteration 195, loss = 1.43243164\n",
      "Iteration 196, loss = 1.43225253\n",
      "Iteration 197, loss = 1.43207620\n",
      "Iteration 198, loss = 1.43188626\n",
      "Iteration 199, loss = 1.43175587\n",
      "Iteration 200, loss = 1.43151707\n",
      "Iteration 201, loss = 1.43131361\n",
      "Iteration 202, loss = 1.43116192\n",
      "Iteration 203, loss = 1.43096028\n",
      "Iteration 204, loss = 1.43078141\n",
      "Iteration 205, loss = 1.43057742\n",
      "Iteration 206, loss = 1.43038446\n",
      "Iteration 207, loss = 1.43019053\n",
      "Iteration 208, loss = 1.43002540\n",
      "Iteration 209, loss = 1.42985084\n",
      "Iteration 210, loss = 1.42972562\n",
      "Iteration 211, loss = 1.42945430\n",
      "Iteration 212, loss = 1.42929811\n",
      "Iteration 213, loss = 1.42922514\n",
      "Iteration 214, loss = 1.42891070\n",
      "Iteration 215, loss = 1.42880069\n",
      "Iteration 216, loss = 1.42859646\n",
      "Iteration 217, loss = 1.42836026\n",
      "Iteration 218, loss = 1.42824587\n",
      "Iteration 219, loss = 1.42802871\n",
      "Iteration 220, loss = 1.42782909\n",
      "Iteration 221, loss = 1.42767524\n",
      "Iteration 222, loss = 1.42749886\n",
      "Iteration 223, loss = 1.42730416\n",
      "Iteration 224, loss = 1.42711381\n",
      "Iteration 225, loss = 1.42702599\n",
      "Iteration 226, loss = 1.42678117\n",
      "Iteration 227, loss = 1.42659523\n",
      "Iteration 228, loss = 1.42643310\n",
      "Iteration 229, loss = 1.42629424\n",
      "Iteration 230, loss = 1.42602718\n",
      "Iteration 231, loss = 1.42588308\n",
      "Iteration 232, loss = 1.42575613\n",
      "Iteration 233, loss = 1.42553726\n",
      "Iteration 234, loss = 1.42539171\n",
      "Iteration 235, loss = 1.42519723\n",
      "Iteration 236, loss = 1.42499932\n",
      "Iteration 237, loss = 1.42493237\n",
      "Iteration 238, loss = 1.42467456\n",
      "Iteration 239, loss = 1.42452280\n",
      "Iteration 240, loss = 1.42435416\n",
      "Iteration 241, loss = 1.42415378\n",
      "Iteration 242, loss = 1.42397437\n",
      "Iteration 243, loss = 1.42381525\n",
      "Iteration 244, loss = 1.42366335\n",
      "Iteration 245, loss = 1.42352721\n",
      "Iteration 246, loss = 1.42334972\n",
      "Iteration 247, loss = 1.42315712\n",
      "Iteration 248, loss = 1.42297127\n",
      "Iteration 249, loss = 1.42285250\n",
      "Iteration 250, loss = 1.42265442\n",
      "Iteration 251, loss = 1.42248641\n",
      "Iteration 252, loss = 1.42229819\n",
      "Iteration 253, loss = 1.42223298\n",
      "Iteration 254, loss = 1.42198232\n",
      "Iteration 255, loss = 1.42181457\n",
      "Iteration 256, loss = 1.42166102\n",
      "Iteration 257, loss = 1.42148254\n",
      "Iteration 258, loss = 1.42132019\n",
      "Iteration 259, loss = 1.42123781\n",
      "Iteration 260, loss = 1.42096837\n",
      "Iteration 261, loss = 1.42089180\n",
      "Iteration 262, loss = 1.42065749\n",
      "Iteration 263, loss = 1.42052845\n",
      "Iteration 264, loss = 1.42034774\n",
      "Iteration 265, loss = 1.42020846\n",
      "Iteration 266, loss = 1.41999299\n",
      "Iteration 267, loss = 1.41981942\n",
      "Iteration 268, loss = 1.41968391\n",
      "Iteration 269, loss = 1.41954568\n",
      "Iteration 270, loss = 1.41935774\n",
      "Iteration 271, loss = 1.41923281\n",
      "Iteration 272, loss = 1.41907513\n",
      "Iteration 273, loss = 1.41887679\n",
      "Iteration 274, loss = 1.41869653\n",
      "Iteration 275, loss = 1.41864842\n",
      "Iteration 276, loss = 1.41842841\n",
      "Iteration 277, loss = 1.41828910\n",
      "Iteration 278, loss = 1.41809058\n",
      "Iteration 279, loss = 1.41793083\n",
      "Iteration 280, loss = 1.41778453\n",
      "Iteration 281, loss = 1.41763870\n",
      "Iteration 282, loss = 1.41743769\n",
      "Iteration 283, loss = 1.41745328\n",
      "Iteration 284, loss = 1.41717548\n",
      "Iteration 285, loss = 1.41703438\n",
      "Iteration 286, loss = 1.41680007\n",
      "Iteration 287, loss = 1.41666765\n",
      "Iteration 288, loss = 1.41649521\n",
      "Iteration 289, loss = 1.41636839\n",
      "Iteration 290, loss = 1.41618032\n",
      "Iteration 291, loss = 1.41607475\n",
      "Iteration 292, loss = 1.41586183\n",
      "Iteration 293, loss = 1.41572336\n",
      "Iteration 294, loss = 1.41558266\n",
      "Iteration 295, loss = 1.41542140\n",
      "Iteration 296, loss = 1.41527800\n",
      "Iteration 297, loss = 1.41513808\n",
      "Iteration 298, loss = 1.41506072\n",
      "Iteration 299, loss = 1.41482541\n",
      "Iteration 300, loss = 1.41463448\n",
      "Iteration 301, loss = 1.41457200\n",
      "Iteration 302, loss = 1.41437695\n",
      "Iteration 303, loss = 1.41419840\n",
      "Iteration 304, loss = 1.41412576\n",
      "Iteration 305, loss = 1.41408142\n",
      "Iteration 306, loss = 1.41373316\n",
      "Iteration 307, loss = 1.41363672\n",
      "Iteration 308, loss = 1.41350987\n",
      "Iteration 309, loss = 1.41335176\n",
      "Iteration 310, loss = 1.41314810\n",
      "Iteration 311, loss = 1.41303105\n",
      "Iteration 312, loss = 1.41286960\n",
      "Iteration 313, loss = 1.41271987\n",
      "Iteration 314, loss = 1.41261548\n",
      "Iteration 315, loss = 1.41242869\n",
      "Iteration 316, loss = 1.41231722\n",
      "Iteration 317, loss = 1.41214969\n",
      "Iteration 318, loss = 1.41202823\n",
      "Iteration 319, loss = 1.41186642\n",
      "Iteration 320, loss = 1.41170559\n",
      "Iteration 321, loss = 1.41158734\n",
      "Iteration 322, loss = 1.41150481\n",
      "Iteration 323, loss = 1.41133658\n",
      "Iteration 324, loss = 1.41121431\n",
      "Iteration 325, loss = 1.41107319\n",
      "Iteration 326, loss = 1.41091205\n",
      "Iteration 327, loss = 1.41077829\n",
      "Iteration 328, loss = 1.41065038\n",
      "Iteration 329, loss = 1.41056618\n",
      "Iteration 330, loss = 1.41040137\n",
      "Iteration 331, loss = 1.41020572\n",
      "Iteration 332, loss = 1.41011480\n",
      "Iteration 333, loss = 1.41000309\n",
      "Iteration 334, loss = 1.40980687\n",
      "Iteration 335, loss = 1.40970834\n",
      "Iteration 336, loss = 1.40962803\n",
      "Iteration 337, loss = 1.40940829\n",
      "Iteration 338, loss = 1.40931284\n",
      "Iteration 339, loss = 1.40919272\n",
      "Iteration 340, loss = 1.40905216\n",
      "Iteration 341, loss = 1.40891600\n",
      "Iteration 342, loss = 1.40880835\n",
      "Iteration 343, loss = 1.40869933\n",
      "Iteration 344, loss = 1.40851541\n",
      "Iteration 345, loss = 1.40850024\n",
      "Iteration 346, loss = 1.40827577\n",
      "Iteration 347, loss = 1.40817422\n",
      "Iteration 348, loss = 1.40810024\n",
      "Iteration 349, loss = 1.40793835\n",
      "Iteration 350, loss = 1.40785791\n",
      "Iteration 351, loss = 1.40767238\n",
      "Iteration 352, loss = 1.40755981\n",
      "Iteration 353, loss = 1.40755250\n",
      "Iteration 354, loss = 1.40738390\n",
      "Iteration 355, loss = 1.40731347\n",
      "Iteration 356, loss = 1.40718005\n",
      "Iteration 357, loss = 1.40699457\n",
      "Iteration 358, loss = 1.40680504\n",
      "Iteration 359, loss = 1.40670215\n",
      "Iteration 360, loss = 1.40658727\n",
      "Iteration 361, loss = 1.40645566\n",
      "Iteration 362, loss = 1.40641151\n",
      "Iteration 363, loss = 1.40621760\n",
      "Iteration 364, loss = 1.40615810\n",
      "Iteration 365, loss = 1.40600829\n",
      "Iteration 366, loss = 1.40586914\n",
      "Iteration 367, loss = 1.40578466\n",
      "Iteration 368, loss = 1.40568258\n",
      "Iteration 369, loss = 1.40558329\n",
      "Iteration 370, loss = 1.40545155\n",
      "Iteration 371, loss = 1.40529478\n",
      "Iteration 372, loss = 1.40521585\n",
      "Iteration 373, loss = 1.40511336\n",
      "Iteration 374, loss = 1.40497555\n",
      "Iteration 375, loss = 1.40489119\n",
      "Iteration 376, loss = 1.40488655\n",
      "Iteration 377, loss = 1.40466433\n",
      "Iteration 378, loss = 1.40455230\n",
      "Iteration 379, loss = 1.40445821\n",
      "Iteration 380, loss = 1.40433174\n",
      "Iteration 381, loss = 1.40424456\n",
      "Iteration 382, loss = 1.40411519\n",
      "Iteration 383, loss = 1.40400763\n",
      "Iteration 384, loss = 1.40390666\n",
      "Iteration 385, loss = 1.40381289\n",
      "Iteration 386, loss = 1.40371948\n",
      "Iteration 387, loss = 1.40356465\n",
      "Iteration 388, loss = 1.40350424\n",
      "Iteration 389, loss = 1.40344387\n",
      "Iteration 390, loss = 1.40331277\n",
      "Iteration 391, loss = 1.40318136\n",
      "Iteration 392, loss = 1.40309889\n",
      "Iteration 393, loss = 1.40300132\n",
      "Iteration 394, loss = 1.40293181\n",
      "Iteration 395, loss = 1.40281290\n",
      "Iteration 396, loss = 1.40268770\n",
      "Iteration 397, loss = 1.40262000\n",
      "Iteration 398, loss = 1.40260165\n",
      "Iteration 399, loss = 1.40242215\n",
      "Iteration 400, loss = 1.40232612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(256, 128, 64), learning_rate=&#x27;invscaling&#x27;,\n",
       "              learning_rate_init=0.0001, max_iter=400, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(hidden_layer_sizes=(256, 128, 64), learning_rate=&#x27;invscaling&#x27;,\n",
       "              learning_rate_init=0.0001, max_iter=400, verbose=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(256, 128, 64), learning_rate='invscaling',\n",
       "              learning_rate_init=0.0001, max_iter=400, verbose=True)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Abnormal_clasification.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Abnormal_clasification.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_level_decision = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal_level_decision.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = abnormal_level_decision.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.17      0.16      0.16        32\n",
      "           2       0.43      0.71      0.54        48\n",
      "           3       0.31      0.14      0.19        37\n",
      "\n",
      "    accuracy                           0.35       125\n",
      "   macro avg       0.23      0.25      0.22       125\n",
      "weighted avg       0.30      0.35      0.30       125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set ['abnormal_detected'] = level_abnormal.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set.drop(['abnormal_detected'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_abnormal = data_set['ram'] + data_set['cpu'] + data_set['diks'] + data_set['network']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_abnormal = np.array(level_abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_set.values\n",
    "y = level_abnormal.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1973 - loss: 4.0881\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3236 - loss: 3.9810 \n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5372 - loss: 3.8877 \n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4592 - loss: 3.7958 \n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4197 - loss: 3.7160 \n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3733 - loss: 3.6240\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3383 - loss: 3.5575\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3512 - loss: 3.4714 \n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3753 - loss: 3.3920 \n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3605 - loss: 3.2965 \n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3723 - loss: 3.2444 \n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3895 - loss: 3.1412 \n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3803 - loss: 3.0859  \n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4724 - loss: 3.0085\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4788 - loss: 2.9331 \n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4310 - loss: 2.8986\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4754 - loss: 2.8212 \n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5177 - loss: 2.7642 \n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 2.7051 \n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5127 - loss: 2.6281 \n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5705 - loss: 2.5836 \n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6836 - loss: 2.5244 \n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6778 - loss: 2.4711 \n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6615 - loss: 2.4504 \n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7239 - loss: 2.3696 \n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7393 - loss: 2.2996 \n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7737 - loss: 2.2470 \n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7764 - loss: 2.2030\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7737 - loss: 2.1637 \n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7973 - loss: 2.0878\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7922 - loss: 2.0357 \n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 1.9890\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7960 - loss: 1.9648\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8153 - loss: 1.9188\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8763 - loss: 1.8594 \n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8655 - loss: 1.8277 \n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8984 - loss: 1.7403 \n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8678 - loss: 1.7325 \n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8672 - loss: 1.6945 \n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 1.6498 \n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8649 - loss: 1.6188 \n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8847 - loss: 1.5606 \n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8945 - loss: 1.5109 \n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8668 - loss: 1.5069 \n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8809 - loss: 1.4545 \n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 1.4209 \n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8888 - loss: 1.3769 \n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8757 - loss: 1.3689\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8779 - loss: 1.3278 \n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8690 - loss: 1.3161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b919067050>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal_level.fit(x,y,verbose=1,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.array([np.random.randint(0,2) for i in range(1000)])\n",
    "t2 = np.array([np.random.randint(0,2) for i in range(1000)])\n",
    "t3 = np.array([np.random.randint(0,2) for i in range(1000)])\n",
    "t4 = np.array([np.random.randint(0,2) for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame(data={'predict1':t1,'predict2':t2,'predict3':t3,'predict4':t4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict1</th>\n",
       "      <th>predict2</th>\n",
       "      <th>predict3</th>\n",
       "      <th>predict4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     predict1  predict2  predict3  predict4\n",
       "0           0         0         0         1\n",
       "1           1         1         1         1\n",
       "2           1         1         0         1\n",
       "3           1         0         1         1\n",
       "4           1         0         0         1\n",
       "..        ...       ...       ...       ...\n",
       "995         1         0         1         1\n",
       "996         0         1         0         1\n",
       "997         0         0         1         0\n",
       "998         0         1         0         1\n",
       "999         0         0         0         0\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "data_tested = abnormal_level.predict(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08401267, 0.6828091 , 0.21704938, 0.01126552, 0.00486326],\n",
       "       [0.0011687 , 0.00094225, 0.03903582, 0.719497  , 0.23935613],\n",
       "       [0.00420096, 0.00694549, 0.13882533, 0.71750057, 0.13252757],\n",
       "       ...,\n",
       "       [0.11279559, 0.72186846, 0.14688988, 0.01254124, 0.00590483],\n",
       "       [0.0169459 , 0.11021032, 0.78594536, 0.06603029, 0.02086813],\n",
       "       [0.23516886, 0.68991446, 0.05998784, 0.00906582, 0.00586295]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1101: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.59508317\n",
      "Iteration 2, loss = 1.58141025\n",
      "Iteration 3, loss = 1.56831294\n",
      "Iteration 4, loss = 1.55558066\n",
      "Iteration 5, loss = 1.54277150\n",
      "Iteration 6, loss = 1.53076676\n",
      "Iteration 7, loss = 1.51881374\n",
      "Iteration 8, loss = 1.50740606\n",
      "Iteration 9, loss = 1.49614491\n",
      "Iteration 10, loss = 1.48577766\n",
      "Iteration 11, loss = 1.47511299\n",
      "Iteration 12, loss = 1.46500118\n",
      "Iteration 13, loss = 1.45513761\n",
      "Iteration 14, loss = 1.44548638\n",
      "Iteration 15, loss = 1.43629021\n",
      "Iteration 16, loss = 1.42714402\n",
      "Iteration 17, loss = 1.41849200\n",
      "Iteration 18, loss = 1.40934607\n",
      "Iteration 19, loss = 1.40037595\n",
      "Iteration 20, loss = 1.39152946\n",
      "Iteration 21, loss = 1.38295696\n",
      "Iteration 22, loss = 1.37461030\n",
      "Iteration 23, loss = 1.36602321\n",
      "Iteration 24, loss = 1.35767136\n",
      "Iteration 25, loss = 1.34949630\n",
      "Iteration 26, loss = 1.34110640\n",
      "Iteration 27, loss = 1.33281017\n",
      "Iteration 28, loss = 1.32442218\n",
      "Iteration 29, loss = 1.31643249\n",
      "Iteration 30, loss = 1.30831436\n",
      "Iteration 31, loss = 1.30025614\n",
      "Iteration 32, loss = 1.29229947\n",
      "Iteration 33, loss = 1.28407507\n",
      "Iteration 34, loss = 1.27612042\n",
      "Iteration 35, loss = 1.26813223\n",
      "Iteration 36, loss = 1.26006141\n",
      "Iteration 37, loss = 1.25208473\n",
      "Iteration 38, loss = 1.24401468\n",
      "Iteration 39, loss = 1.23608688\n",
      "Iteration 40, loss = 1.22807481\n",
      "Iteration 41, loss = 1.22002488\n",
      "Iteration 42, loss = 1.21198096\n",
      "Iteration 43, loss = 1.20396724\n",
      "Iteration 44, loss = 1.19591510\n",
      "Iteration 45, loss = 1.18775998\n",
      "Iteration 46, loss = 1.17958147\n",
      "Iteration 47, loss = 1.17136306\n",
      "Iteration 48, loss = 1.16331706\n",
      "Iteration 49, loss = 1.15507264\n",
      "Iteration 50, loss = 1.14696490\n",
      "Iteration 51, loss = 1.13888581\n",
      "Iteration 52, loss = 1.13074791\n",
      "Iteration 53, loss = 1.12254677\n",
      "Iteration 54, loss = 1.11431868\n",
      "Iteration 55, loss = 1.10614970\n",
      "Iteration 56, loss = 1.09809502\n",
      "Iteration 57, loss = 1.08971974\n",
      "Iteration 58, loss = 1.08132972\n",
      "Iteration 59, loss = 1.07305962\n",
      "Iteration 60, loss = 1.06463346\n",
      "Iteration 61, loss = 1.05603225\n",
      "Iteration 62, loss = 1.04757806\n",
      "Iteration 63, loss = 1.03904694\n",
      "Iteration 64, loss = 1.03064854\n",
      "Iteration 65, loss = 1.02215997\n",
      "Iteration 66, loss = 1.01362086\n",
      "Iteration 67, loss = 1.00508028\n",
      "Iteration 68, loss = 0.99648898\n",
      "Iteration 69, loss = 0.98763788\n",
      "Iteration 70, loss = 0.97894762\n",
      "Iteration 71, loss = 0.97007937\n",
      "Iteration 72, loss = 0.96110755\n",
      "Iteration 73, loss = 0.95220362\n",
      "Iteration 74, loss = 0.94350226\n",
      "Iteration 75, loss = 0.93464926\n",
      "Iteration 76, loss = 0.92585041\n",
      "Iteration 77, loss = 0.91686426\n",
      "Iteration 78, loss = 0.90806243\n",
      "Iteration 79, loss = 0.89916249\n",
      "Iteration 80, loss = 0.89020234\n",
      "Iteration 81, loss = 0.88119668\n",
      "Iteration 82, loss = 0.87223856\n",
      "Iteration 83, loss = 0.86321123\n",
      "Iteration 84, loss = 0.85427417\n",
      "Iteration 85, loss = 0.84527232\n",
      "Iteration 86, loss = 0.83631812\n",
      "Iteration 87, loss = 0.82747913\n",
      "Iteration 88, loss = 0.81855000\n",
      "Iteration 89, loss = 0.80957245\n",
      "Iteration 90, loss = 0.80070805\n",
      "Iteration 91, loss = 0.79192651\n",
      "Iteration 92, loss = 0.78314949\n",
      "Iteration 93, loss = 0.77436906\n",
      "Iteration 94, loss = 0.76560059\n",
      "Iteration 95, loss = 0.75692120\n",
      "Iteration 96, loss = 0.74827088\n",
      "Iteration 97, loss = 0.73971556\n",
      "Iteration 98, loss = 0.73128875\n",
      "Iteration 99, loss = 0.72277948\n",
      "Iteration 100, loss = 0.71421655\n",
      "Iteration 101, loss = 0.70581649\n",
      "Iteration 102, loss = 0.69737721\n",
      "Iteration 103, loss = 0.68890174\n",
      "Iteration 104, loss = 0.68054777\n",
      "Iteration 105, loss = 0.67217616\n",
      "Iteration 106, loss = 0.66385261\n",
      "Iteration 107, loss = 0.65556178\n",
      "Iteration 108, loss = 0.64739893\n",
      "Iteration 109, loss = 0.63915276\n",
      "Iteration 110, loss = 0.63087340\n",
      "Iteration 111, loss = 0.62266819\n",
      "Iteration 112, loss = 0.61463106\n",
      "Iteration 113, loss = 0.60666636\n",
      "Iteration 114, loss = 0.59866548\n",
      "Iteration 115, loss = 0.59078490\n",
      "Iteration 116, loss = 0.58305403\n",
      "Iteration 117, loss = 0.57538905\n",
      "Iteration 118, loss = 0.56781260\n",
      "Iteration 119, loss = 0.56021994\n",
      "Iteration 120, loss = 0.55276829\n",
      "Iteration 121, loss = 0.54527560\n",
      "Iteration 122, loss = 0.53804731\n",
      "Iteration 123, loss = 0.53071614\n",
      "Iteration 124, loss = 0.52356951\n",
      "Iteration 125, loss = 0.51650773\n",
      "Iteration 126, loss = 0.50958147\n",
      "Iteration 127, loss = 0.50254163\n",
      "Iteration 128, loss = 0.49571232\n",
      "Iteration 129, loss = 0.48904280\n",
      "Iteration 130, loss = 0.48236037\n",
      "Iteration 131, loss = 0.47580745\n",
      "Iteration 132, loss = 0.46921547\n",
      "Iteration 133, loss = 0.46279041\n",
      "Iteration 134, loss = 0.45627774\n",
      "Iteration 135, loss = 0.44973300\n",
      "Iteration 136, loss = 0.44332196\n",
      "Iteration 137, loss = 0.43686248\n",
      "Iteration 138, loss = 0.43060129\n",
      "Iteration 139, loss = 0.42461122\n",
      "Iteration 140, loss = 0.41853672\n",
      "Iteration 141, loss = 0.41229854\n",
      "Iteration 142, loss = 0.40613176\n",
      "Iteration 143, loss = 0.40003192\n",
      "Iteration 144, loss = 0.39403684\n",
      "Iteration 145, loss = 0.38808369\n",
      "Iteration 146, loss = 0.38231698\n",
      "Iteration 147, loss = 0.37644009\n",
      "Iteration 148, loss = 0.37050237\n",
      "Iteration 149, loss = 0.36453092\n",
      "Iteration 150, loss = 0.35856333\n",
      "Iteration 151, loss = 0.35289885\n",
      "Iteration 152, loss = 0.34746510\n",
      "Iteration 153, loss = 0.34210969\n",
      "Iteration 154, loss = 0.33675345\n",
      "Iteration 155, loss = 0.33147124\n",
      "Iteration 156, loss = 0.32612800\n",
      "Iteration 157, loss = 0.32099468\n",
      "Iteration 158, loss = 0.31583992\n",
      "Iteration 159, loss = 0.31083850\n",
      "Iteration 160, loss = 0.30580290\n",
      "Iteration 161, loss = 0.30088612\n",
      "Iteration 162, loss = 0.29605554\n",
      "Iteration 163, loss = 0.29123566\n",
      "Iteration 164, loss = 0.28653876\n",
      "Iteration 165, loss = 0.28190130\n",
      "Iteration 166, loss = 0.27733919\n",
      "Iteration 167, loss = 0.27292809\n",
      "Iteration 168, loss = 0.26826676\n",
      "Iteration 169, loss = 0.26392915\n",
      "Iteration 170, loss = 0.25944618\n",
      "Iteration 171, loss = 0.25505235\n",
      "Iteration 172, loss = 0.25073889\n",
      "Iteration 173, loss = 0.24650778\n",
      "Iteration 174, loss = 0.24252370\n",
      "Iteration 175, loss = 0.23839118\n",
      "Iteration 176, loss = 0.23433572\n",
      "Iteration 177, loss = 0.23032415\n",
      "Iteration 178, loss = 0.22642382\n",
      "Iteration 179, loss = 0.22255306\n",
      "Iteration 180, loss = 0.21870567\n",
      "Iteration 181, loss = 0.21504199\n",
      "Iteration 182, loss = 0.21135058\n",
      "Iteration 183, loss = 0.20771917\n",
      "Iteration 184, loss = 0.20423798\n",
      "Iteration 185, loss = 0.20066180\n",
      "Iteration 186, loss = 0.19722441\n",
      "Iteration 187, loss = 0.19377558\n",
      "Iteration 188, loss = 0.19044340\n",
      "Iteration 189, loss = 0.18709053\n",
      "Iteration 190, loss = 0.18381696\n",
      "Iteration 191, loss = 0.18054652\n",
      "Iteration 192, loss = 0.17736544\n",
      "Iteration 193, loss = 0.17428445\n",
      "Iteration 194, loss = 0.17113900\n",
      "Iteration 195, loss = 0.16808047\n",
      "Iteration 196, loss = 0.16511059\n",
      "Iteration 197, loss = 0.16222652\n",
      "Iteration 198, loss = 0.15935207\n",
      "Iteration 199, loss = 0.15650874\n",
      "Iteration 200, loss = 0.15378799\n",
      "Iteration 201, loss = 0.15111565\n",
      "Iteration 202, loss = 0.14837247\n",
      "Iteration 203, loss = 0.14577543\n",
      "Iteration 204, loss = 0.14329784\n",
      "Iteration 205, loss = 0.14073206\n",
      "Iteration 206, loss = 0.13829469\n",
      "Iteration 207, loss = 0.13586822\n",
      "Iteration 208, loss = 0.13358875\n",
      "Iteration 209, loss = 0.13122919\n",
      "Iteration 210, loss = 0.12891575\n",
      "Iteration 211, loss = 0.12668948\n",
      "Iteration 212, loss = 0.12448796\n",
      "Iteration 213, loss = 0.12238385\n",
      "Iteration 214, loss = 0.12026093\n",
      "Iteration 215, loss = 0.11816841\n",
      "Iteration 216, loss = 0.11614555\n",
      "Iteration 217, loss = 0.11420357\n",
      "Iteration 218, loss = 0.11221059\n",
      "Iteration 219, loss = 0.11032952\n",
      "Iteration 220, loss = 0.10842674\n",
      "Iteration 221, loss = 0.10661889\n",
      "Iteration 222, loss = 0.10488687\n",
      "Iteration 223, loss = 0.10309312\n",
      "Iteration 224, loss = 0.10133977\n",
      "Iteration 225, loss = 0.09964975\n",
      "Iteration 226, loss = 0.09800222\n",
      "Iteration 227, loss = 0.09637618\n",
      "Iteration 228, loss = 0.09480594\n",
      "Iteration 229, loss = 0.09322553\n",
      "Iteration 230, loss = 0.09171287\n",
      "Iteration 231, loss = 0.09019019\n",
      "Iteration 232, loss = 0.08873641\n",
      "Iteration 233, loss = 0.08731277\n",
      "Iteration 234, loss = 0.08586836\n",
      "Iteration 235, loss = 0.08441047\n",
      "Iteration 236, loss = 0.08299822\n",
      "Iteration 237, loss = 0.08160677\n",
      "Iteration 238, loss = 0.08025673\n",
      "Iteration 239, loss = 0.07895406\n",
      "Iteration 240, loss = 0.07765725\n",
      "Iteration 241, loss = 0.07641252\n",
      "Iteration 242, loss = 0.07517538\n",
      "Iteration 243, loss = 0.07397764\n",
      "Iteration 244, loss = 0.07278875\n",
      "Iteration 245, loss = 0.07164345\n",
      "Iteration 246, loss = 0.07049536\n",
      "Iteration 247, loss = 0.06937432\n",
      "Iteration 248, loss = 0.06828474\n",
      "Iteration 249, loss = 0.06721167\n",
      "Iteration 250, loss = 0.06616487\n",
      "Iteration 251, loss = 0.06513230\n",
      "Iteration 252, loss = 0.06414836\n",
      "Iteration 253, loss = 0.06316819\n",
      "Iteration 254, loss = 0.06220489\n",
      "Iteration 255, loss = 0.06124376\n",
      "Iteration 256, loss = 0.06030850\n",
      "Iteration 257, loss = 0.05940552\n",
      "Iteration 258, loss = 0.05851337\n",
      "Iteration 259, loss = 0.05763933\n",
      "Iteration 260, loss = 0.05678310\n",
      "Iteration 261, loss = 0.05595122\n",
      "Iteration 262, loss = 0.05511526\n",
      "Iteration 263, loss = 0.05430694\n",
      "Iteration 264, loss = 0.05352560\n",
      "Iteration 265, loss = 0.05275391\n",
      "Iteration 266, loss = 0.05200040\n",
      "Iteration 267, loss = 0.05125146\n",
      "Iteration 268, loss = 0.05053362\n",
      "Iteration 269, loss = 0.04981067\n",
      "Iteration 270, loss = 0.04910491\n",
      "Iteration 271, loss = 0.04843038\n",
      "Iteration 272, loss = 0.04773523\n",
      "Iteration 273, loss = 0.04706912\n",
      "Iteration 274, loss = 0.04641653\n",
      "Iteration 275, loss = 0.04577316\n",
      "Iteration 276, loss = 0.04514108\n",
      "Iteration 277, loss = 0.04452475\n",
      "Iteration 278, loss = 0.04391233\n",
      "Iteration 279, loss = 0.04333459\n",
      "Iteration 280, loss = 0.04273498\n",
      "Iteration 281, loss = 0.04216866\n",
      "Iteration 282, loss = 0.04160252\n",
      "Iteration 283, loss = 0.04106279\n",
      "Iteration 284, loss = 0.04050350\n",
      "Iteration 285, loss = 0.03997815\n",
      "Iteration 286, loss = 0.03946164\n",
      "Iteration 287, loss = 0.03894886\n",
      "Iteration 288, loss = 0.03843580\n",
      "Iteration 289, loss = 0.03794407\n",
      "Iteration 290, loss = 0.03745452\n",
      "Iteration 291, loss = 0.03696965\n",
      "Iteration 292, loss = 0.03650241\n",
      "Iteration 293, loss = 0.03603843\n",
      "Iteration 294, loss = 0.03558907\n",
      "Iteration 295, loss = 0.03513549\n",
      "Iteration 296, loss = 0.03469776\n",
      "Iteration 297, loss = 0.03426904\n",
      "Iteration 298, loss = 0.03384190\n",
      "Iteration 299, loss = 0.03343369\n",
      "Iteration 300, loss = 0.03301664\n",
      "Iteration 301, loss = 0.03261399\n",
      "Iteration 302, loss = 0.03221143\n",
      "Iteration 303, loss = 0.03182192\n",
      "Iteration 304, loss = 0.03143968\n",
      "Iteration 305, loss = 0.03106321\n",
      "Iteration 306, loss = 0.03068769\n",
      "Iteration 307, loss = 0.03032249\n",
      "Iteration 308, loss = 0.02996266\n",
      "Iteration 309, loss = 0.02960705\n",
      "Iteration 310, loss = 0.02926070\n",
      "Iteration 311, loss = 0.02892659\n",
      "Iteration 312, loss = 0.02858823\n",
      "Iteration 313, loss = 0.02825941\n",
      "Iteration 314, loss = 0.02792917\n",
      "Iteration 315, loss = 0.02760500\n",
      "Iteration 316, loss = 0.02728722\n",
      "Iteration 317, loss = 0.02697646\n",
      "Iteration 318, loss = 0.02666365\n",
      "Iteration 319, loss = 0.02636210\n",
      "Iteration 320, loss = 0.02607019\n",
      "Iteration 321, loss = 0.02577957\n",
      "Iteration 322, loss = 0.02549535\n",
      "Iteration 323, loss = 0.02521827\n",
      "Iteration 324, loss = 0.02494070\n",
      "Iteration 325, loss = 0.02467905\n",
      "Iteration 326, loss = 0.02440830\n",
      "Iteration 327, loss = 0.02414196\n",
      "Iteration 328, loss = 0.02388347\n",
      "Iteration 329, loss = 0.02362275\n",
      "Iteration 330, loss = 0.02337140\n",
      "Iteration 331, loss = 0.02312258\n",
      "Iteration 332, loss = 0.02287590\n",
      "Iteration 333, loss = 0.02263522\n",
      "Iteration 334, loss = 0.02239542\n",
      "Iteration 335, loss = 0.02215855\n",
      "Iteration 336, loss = 0.02193007\n",
      "Iteration 337, loss = 0.02170138\n",
      "Iteration 338, loss = 0.02147708\n",
      "Iteration 339, loss = 0.02125568\n",
      "Iteration 340, loss = 0.02103942\n",
      "Iteration 341, loss = 0.02082334\n",
      "Iteration 342, loss = 0.02061358\n",
      "Iteration 343, loss = 0.02040450\n",
      "Iteration 344, loss = 0.02019521\n",
      "Iteration 345, loss = 0.01999280\n",
      "Iteration 346, loss = 0.01979335\n",
      "Iteration 347, loss = 0.01959339\n",
      "Iteration 348, loss = 0.01939817\n",
      "Iteration 349, loss = 0.01920189\n",
      "Iteration 350, loss = 0.01901551\n",
      "Iteration 351, loss = 0.01882610\n",
      "Iteration 352, loss = 0.01864224\n",
      "Iteration 353, loss = 0.01845984\n",
      "Iteration 354, loss = 0.01828100\n",
      "Iteration 355, loss = 0.01810266\n",
      "Iteration 356, loss = 0.01792921\n",
      "Iteration 357, loss = 0.01775600\n",
      "Iteration 358, loss = 0.01758442\n",
      "Iteration 359, loss = 0.01742017\n",
      "Iteration 360, loss = 0.01725220\n",
      "Iteration 361, loss = 0.01709217\n",
      "Iteration 362, loss = 0.01692994\n",
      "Iteration 363, loss = 0.01677128\n",
      "Iteration 364, loss = 0.01661825\n",
      "Iteration 365, loss = 0.01646320\n",
      "Iteration 366, loss = 0.01630981\n",
      "Iteration 367, loss = 0.01615964\n",
      "Iteration 368, loss = 0.01600957\n",
      "Iteration 369, loss = 0.01586288\n",
      "Iteration 370, loss = 0.01571753\n",
      "Iteration 371, loss = 0.01557503\n",
      "Iteration 372, loss = 0.01543229\n",
      "Iteration 373, loss = 0.01529274\n",
      "Iteration 374, loss = 0.01515354\n",
      "Iteration 375, loss = 0.01501802\n",
      "Iteration 376, loss = 0.01488346\n",
      "Iteration 377, loss = 0.01475053\n",
      "Iteration 378, loss = 0.01461870\n",
      "Iteration 379, loss = 0.01449077\n",
      "Iteration 380, loss = 0.01435973\n",
      "Iteration 381, loss = 0.01423138\n",
      "Iteration 382, loss = 0.01410551\n",
      "Iteration 383, loss = 0.01397823\n",
      "Iteration 384, loss = 0.01385565\n",
      "Iteration 385, loss = 0.01373305\n",
      "Iteration 386, loss = 0.01361451\n",
      "Iteration 387, loss = 0.01349356\n",
      "Iteration 388, loss = 0.01337549\n",
      "Iteration 389, loss = 0.01326039\n",
      "Iteration 390, loss = 0.01314642\n",
      "Iteration 391, loss = 0.01303238\n",
      "Iteration 392, loss = 0.01292111\n",
      "Iteration 393, loss = 0.01281078\n",
      "Iteration 394, loss = 0.01270221\n",
      "Iteration 395, loss = 0.01259465\n",
      "Iteration 396, loss = 0.01248743\n",
      "Iteration 397, loss = 0.01238280\n",
      "Iteration 398, loss = 0.01227796\n",
      "Iteration 399, loss = 0.01217532\n",
      "Iteration 400, loss = 0.01207341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(256, 128, 64), learning_rate=&#x27;invscaling&#x27;,\n",
       "              learning_rate_init=0.0001, max_iter=400, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(hidden_layer_sizes=(256, 128, 64), learning_rate=&#x27;invscaling&#x27;,\n",
       "              learning_rate_init=0.0001, max_iter=400, verbose=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(256, 128, 64), learning_rate='invscaling',\n",
       "              learning_rate_init=0.0001, max_iter=400, verbose=True)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Abnormal_clasification.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 3, 3, 2, 1, 2, 1, 2, 1, 2, 3, 3, 3, 0, 1, 1, 1, 1, 0, 0, 2,\n",
       "       2, 3, 3, 2, 1, 1, 0, 4, 3, 1, 3, 2, 1, 3, 3, 2, 1, 0, 2, 0, 1, 2,\n",
       "       0, 2, 3, 1, 3, 2, 3, 1, 2, 2, 2, 2, 3, 4, 0, 1, 2, 2, 2, 2, 3, 0,\n",
       "       0, 1, 3, 0, 4, 4, 0, 3, 1, 3, 2, 4, 1, 3, 1, 3, 3, 2, 3, 3, 1, 0,\n",
       "       4, 1, 2, 1, 4, 3, 3, 4, 2, 4, 3, 3, 1, 4, 1, 2, 3, 2, 1, 1, 1, 3,\n",
       "       3, 2, 0, 3, 2, 4, 1, 0, 2, 1, 2, 1, 1, 1, 2, 2, 2, 3, 1, 3, 3, 1,\n",
       "       3, 2, 2, 1, 1, 1, 3, 3, 2, 0, 1, 2, 2, 0, 3, 4, 3, 1, 2, 0, 3, 2,\n",
       "       2, 1, 3, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 2, 2, 3, 2, 3,\n",
       "       2, 2, 2, 2, 1, 2, 1, 2, 3, 1, 4, 3, 1, 1, 0, 3, 2, 1, 0, 2, 2, 2,\n",
       "       1, 0, 1, 1, 2, 3, 3, 2, 1, 1, 4, 3, 2, 4, 1, 3, 3, 2, 3, 1, 2, 1,\n",
       "       2, 3, 2, 2, 1, 4, 1, 2, 2, 0, 2, 1, 4, 3, 0, 1, 2, 3, 1, 3, 3, 3,\n",
       "       1, 3, 4, 2, 1, 3, 1, 1, 1, 2, 0, 1, 3, 2, 2, 2, 2, 2, 2, 3, 2, 3,\n",
       "       3, 3, 1, 2, 2, 4, 1, 2, 3, 2, 4, 1, 2, 1, 4, 4, 1, 3, 1, 2, 2, 2,\n",
       "       3, 1, 4, 2, 0, 0, 2, 4, 3, 1, 2, 4, 2, 3, 1, 2, 2, 1, 2, 2, 1, 0,\n",
       "       3, 3, 1, 1, 0, 1, 3, 1, 4, 2, 4, 2, 3, 2, 3, 2, 3, 0, 3, 3, 2, 2,\n",
       "       4, 2, 4, 2, 2, 1, 2, 1, 1, 3, 1, 1, 1, 2, 2, 1, 3, 1, 1, 3, 3, 2,\n",
       "       3, 2, 2, 2, 2, 2, 3, 1, 3, 2, 3, 2, 3, 0, 4, 2, 3, 0, 1, 2, 1, 1,\n",
       "       3, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 3, 2, 3, 2,\n",
       "       0, 3, 4, 2, 3, 2, 1, 2, 1, 2, 1, 2, 1, 4, 3, 2, 1, 1, 0, 3, 1, 2,\n",
       "       4, 2, 1, 3, 2, 0, 2, 1, 2, 3, 1, 3, 0, 2, 2, 2, 2, 0, 3, 2, 1, 1,\n",
       "       3, 2, 1, 3, 1, 2, 3, 2, 1, 1, 4, 2, 4, 1, 1, 1, 1, 3, 2, 1, 3, 3,\n",
       "       3, 2, 3, 2, 0, 0, 3, 1, 1, 1, 4, 1, 0, 3, 1, 3, 4, 3, 2, 0, 0, 3,\n",
       "       2, 2, 1, 2, 3, 1, 2, 3, 1, 3, 2, 2, 2, 1, 1, 2, 3, 1, 3, 2, 2, 1,\n",
       "       4, 1, 4, 3, 1, 2, 2, 1, 0, 2, 4, 2, 3, 0, 3, 3, 3, 4, 2, 0, 2, 2,\n",
       "       1, 3, 1, 2, 4, 3, 3, 1, 2, 3, 2, 2, 2, 1, 1, 3, 2, 1, 0, 0, 1, 1,\n",
       "       1, 2, 1, 2, 1, 3, 3, 2, 3, 3, 1, 1, 0, 1, 1, 2, 3, 4, 2, 2, 2, 3,\n",
       "       2, 4, 1, 2, 2, 1, 2, 2, 2, 2, 3, 4, 4, 1, 1, 2, 2, 3, 1, 1, 1, 2,\n",
       "       1, 2, 0, 2, 3, 2, 1, 2, 2, 0, 3, 3, 1, 3, 2, 2, 3, 2, 2, 3, 2, 3,\n",
       "       3, 4, 1, 1, 3, 1, 1, 3, 3, 0, 1, 3, 2, 2, 3, 0, 2, 1, 0, 2, 1, 2,\n",
       "       4, 3, 2, 1, 2, 2, 3, 0, 2, 2, 2, 2, 2, 2, 3, 1, 3, 2, 4, 3, 3, 0,\n",
       "       4, 2, 2, 2, 2, 2, 1, 2, 4, 2, 1, 3, 3, 2, 1, 2, 3, 4, 2, 2, 2, 1,\n",
       "       1, 2, 2, 2, 3, 2, 0, 2, 2, 2, 1, 1, 3, 1, 2, 1, 1, 3, 2, 2, 2, 1,\n",
       "       4, 3, 4, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 1, 3, 2, 3, 3, 1, 1, 3,\n",
       "       3, 1, 1, 3, 2, 3, 2, 1, 3, 2, 1, 2, 2, 1, 3, 2, 0, 1, 1, 1, 3, 3,\n",
       "       3, 3, 1, 3, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2, 4, 3, 4,\n",
       "       1, 2, 3, 3, 3, 1, 3, 3, 3, 1, 1, 3, 3, 3, 2, 3, 2, 0, 1, 3, 3, 2,\n",
       "       3, 1, 3, 3, 3, 0, 2, 2, 2, 1, 1, 2, 1, 2, 1, 3, 1, 1, 3, 2, 3, 0,\n",
       "       3, 1, 2, 2, 1, 1, 3, 1, 2, 0, 1, 0, 1, 0, 3, 0, 0, 2, 3, 3, 0, 2,\n",
       "       2, 2, 2, 1, 3, 1, 2, 3, 3, 1, 3, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 3,\n",
       "       2, 3, 1, 0, 4, 4, 1, 3, 4, 3, 3, 2, 3, 2, 2, 3, 4, 2, 3, 2, 2, 2,\n",
       "       4, 2, 1, 0, 2, 2, 3, 3, 2, 0, 3, 2, 3, 2, 3, 2, 2, 0, 3, 3, 1, 3,\n",
       "       3, 2, 3, 3, 3, 2, 3, 3, 2, 2, 2, 0, 3, 1, 4, 3, 2, 2, 3, 3, 2, 3,\n",
       "       1, 2, 0, 2, 3, 2, 2, 2, 2, 1, 2, 2, 2, 1, 4, 4, 3, 2, 4, 1, 1, 4,\n",
       "       3, 1, 2, 3, 1, 2, 1, 2, 3, 3, 2, 1, 2, 3, 0, 3, 3, 1, 2, 2, 2, 2,\n",
       "       4, 2, 2, 2, 1, 3, 0, 3, 2, 2, 2, 1, 3, 3, 4, 2, 2, 0, 1, 1, 2, 2,\n",
       "       3, 1, 3, 2, 1, 3, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Abnormal_clasification.predict(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abnormal_level_decision.pkl']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(abnormal_level_decision,'abnormal_level_decision.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameter_destructed = np.array([np.random.randint(1,100) / 100 for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameter_abnormal = np.array([np.random.randint(0,4) for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = []\n",
    "for i in range(len(Parameter_abnormal)):\n",
    "    if Parameter_abnormal[i] > 2 and Parameter_destructed[i] < 0.75 : \n",
    "        classification.append(0)\n",
    "    else : \n",
    "        classification.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = np.array(classification).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(data={'Parameter_destructed' : Parameter_destructed,'Parameter_abnormal' : Parameter_abnormal})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.values\n",
    "y = classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_linear = keras.Sequential(\n",
    "    [keras.Input(shape=(2,)),\n",
    "     layers.Dense(256,activation='relu'),\n",
    "     layers.Dense(128,activation='relu'),\n",
    "     layers.Dense(64,activation='relu'),\n",
    "     layers.Dense(1,activation='sigmoid')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_linear.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,985</span> (164.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41,985\u001b[0m (164.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,985</span> (164.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,985\u001b[0m (164.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decision_linear.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 2s - 72ms/step - accuracy: 0.1630 - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "32/32 - 0s - 12ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "32/32 - 0s - 5ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "32/32 - 0s - 6ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "32/32 - 0s - 6ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "32/32 - 0s - 7ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "32/32 - 0s - 5ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "32/32 - 0s - 5ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "32/32 - 0s - 5ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "32/32 - 0s - 5ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "32/32 - 0s - 6ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "32/32 - 0s - 4ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "32/32 - 0s - 3ms/step - accuracy: 0.1620 - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x246e1098470>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_linear.fit(x,y,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = np.array(([[0.12,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78, 2.  ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_vector = SVC(kernel='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m machine_vector\u001b[38;5;241m.\u001b[39mfit(\u001b[43mx\u001b[49m,y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "machine_vector.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([np.random.randint(1,100)/100 for i in range(100)])\n",
    "x_test2 = np.array([np.random.randint(0,4) for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame(data={'data1' : x_test,'data2' : x_test2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.53</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    data1  data2\n",
       "0    0.89      0\n",
       "1    0.40      3\n",
       "2    0.63      1\n",
       "3    0.97      3\n",
       "4    0.25      2\n",
       "..    ...    ...\n",
       "95   0.90      1\n",
       "96   0.99      1\n",
       "97   0.53      3\n",
       "98   0.27      1\n",
       "99   0.64      0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_vector.predict(target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['confimer_machine.pkl']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(machine_vector,'confimer_machine.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
